{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yaKy7HosA1K8"
      },
      "outputs": [],
      "source": [
        "#Q.1 What is deep learning, and how is it connected to artificial intelligence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is Deep Learning?\n",
        "# Deep learning is a subset of machine learning, which itself is a part of artificial intelligence (AI). It involves using neural networks to model complex patterns in large amounts of data. These neural networks are inspired by the structure and functioning of the human brain, and they consist of multiple layers of interconnected nodes (neurons). These layers are called deep layers, which is why the term \"deep learning\" is used.\n",
        "\n",
        "# Deep learning models learn to automatically extract features from raw data without needing explicit programming or feature engineering. The most common types of deep learning architectures include:\n",
        "\n",
        "# Convolutional Neural Networks (CNNs): Primarily used for image and video recognition.\n",
        "# Recurrent Neural Networks (RNNs): Suitable for sequential data like text or time series.\n",
        "# Transformers: Powerful models for natural language processing (NLP) tasks.\n",
        "# Generative Adversarial Networks (GANs): Used for generating new data that mimics real data.\n",
        "# Deep learning requires vast amounts of labeled data and computational power, often utilizing Graphics Processing Units (GPUs) for faster processing.\n",
        "\n",
        "# How is Deep Learning Connected to Artificial Intelligence?\n",
        "# Deep learning is a critical component of AI, and it has contributed significantly to advancements in the field. AI encompasses a broad range of techniques that aim to make machines smart, and deep learning provides some of the most powerful tools for achieving this.\n",
        "\n",
        "# Machine Learning vs. Deep Learning: Deep learning is a specialized branch of machine learning. While machine learning techniques use algorithms to learn from data and make predictions or decisions, deep learning goes a step further by automating the extraction of features and learning highly complex representations of data.\n",
        "\n",
        "# Role in AI: Deep learning has enabled AI to tackle problems that were previously difficult or impossible for traditional algorithms to solve. It has led to major breakthroughs in areas like:\n",
        "\n",
        "# Computer Vision: Recognizing objects, faces, and scenes in images and videos.\n",
        "# Natural Language Processing (NLP): Powers applications like chatbots, language translation, and voice assistants.\n",
        "# Autonomous Vehicles: Enabling self-driving cars to navigate and understand their environment."
      ],
      "metadata": {
        "id": "OXnYJJ3PCqyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.2 What is a neural network, and what are the different types of neural networks?"
      ],
      "metadata": {
        "id": "yd3fntDUDAQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a Neural Network?\n",
        "# A neural network is a computational model inspired by the way biological neural networks in the human brain work. It consists of layers of nodes (also called neurons or units) that process information. Each node performs mathematical operations on inputs and sends the output to other nodes in subsequent layers.\n",
        "\n",
        "# A typical neural network is structured as follows:\n",
        "\n",
        "# Input Layer: The initial layer that takes in the data or features to be processed.\n",
        "# Hidden Layers: Layers between the input and output layers, where most of the computation happens. A neural network can have one or more hidden layers, and this depth is what distinguishes deep learning from traditional machine learning.\n",
        "# Output Layer: The final layer that produces the network‚Äôs prediction or classification result.\n",
        "# Each connection between neurons has a weight that adjusts during training to minimize error, and each neuron has a bias term that allows the model to better fit the data. Neural networks learn through a process called backpropagation, where errors are propagated back from the output layer to the input layer, updating the weights to improve performance.\n",
        "\n",
        "# Different Types of Neural Networks\n",
        "# There are several types of neural networks, each suited to different types of tasks. Some of the most common types include:\n",
        "\n",
        "# Feedforward Neural Networks (FNN):\n",
        "\n",
        "# The simplest type of neural network.\n",
        "# Information flows in one direction, from the input layer through the hidden layers to the output layer.\n",
        "# Often used for general classification tasks.\n",
        "# Convolutional Neural Networks (CNN):\n",
        "\n",
        "# Primarily used for image and video processing tasks (such as image classification, object detection, and image segmentation).\n",
        "# CNNs consist of convolutional layers that apply filters to input data (like images) to capture spatial hierarchies in the data.\n",
        "# They use pooling layers to reduce the dimensionality and computational load, and fully connected layers for the final prediction.\n",
        "# Recurrent Neural Networks (RNN):\n",
        "\n",
        "# Designed for sequential data such as time series, text, or speech.\n",
        "# Unlike feedforward networks, RNNs have connections that loop back, allowing information to persist and be used in later computations.\n",
        "# They are ideal for tasks where context or order matters (e.g., language modeling, speech recognition).\n",
        "# Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) are specialized types of RNNs designed to handle long-term dependencies in sequences more effectively.\n",
        "# Generative Adversarial Networks (GAN):\n",
        "\n",
        "# Comprise two neural networks: a generator and a discriminator. The generator creates data (such as images or music), while the discriminator evaluates whether the data is real (from the training set) or fake (generated by the model).\n",
        "# GANs are used for generating realistic synthetic data, including images, text, and even video.\n",
        "# Radial Basis Function Networks (RBFN):\n",
        "\n",
        "# A type of feedforward neural network that uses radial basis functions as activation functions.\n",
        "# Often used for function approximation and classification tasks.\n",
        "# They have a unique architecture with one layer of nodes that measures distances from a central point.\n",
        "# Self-Organizing Maps (SOM):\n",
        "\n",
        "# A type of unsupervised learning neural network that performs clustering and dimensionality reduction.\n",
        "# SOMs map high-dimensional data to lower-dimensional grids (usually 2D) while preserving topological properties.\n",
        "# They are useful for data visualization and clustering.\n",
        "# Transformer Networks:\n",
        "\n",
        "# Primarily used for natural language processing tasks such as machine translation, text generation, and sentiment analysis.\n",
        "# Transformer models (like BERT and GPT) use self-attention mechanisms to weigh the importance of different words or parts of the input when making predictions.\n",
        "# These models have revolutionized NLP by enabling more accurate and efficient language understanding.\n",
        "# Summary of Neural Network Types:\n",
        "# Feedforward Neural Networks (FNN): Basic structure for classification tasks.\n",
        "# Convolutional Neural Networks (CNN): Used for image and video data.\n",
        "# Recurrent Neural Networks (RNN): Suitable for sequential data, such as text or time series.\n",
        "# Generative Adversarial Networks (GAN): Used for generating new data similar to training data.\n",
        "# Radial Basis Function Networks (RBFN): Used for function approximation and classification.\n",
        "# Self-Organizing Maps (SOM): Unsupervised networks for clustering and visualization.\n",
        "# Transformer Networks: Advanced models for natural language processing tasks."
      ],
      "metadata": {
        "id": "Ugd12hWYDK_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.3 What is the mathematical structure of a neural network"
      ],
      "metadata": {
        "id": "LTfaJPf9DUzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Structure and Layers:\n",
        "# A neural network is composed of multiple layers of nodes (also called neurons), organized as:\n",
        "\n",
        "# Input Layer: Represents the input data.\n",
        "# Hidden Layers: Perform intermediate computations. Each hidden layer consists of neurons that compute weighted sums of their inputs, followed by a non-linear activation function.\n",
        "# Output Layer: Produces the final result.\n",
        "# 2. Mathematical Components:\n",
        "# (a) Input Representation:\n",
        "# The input is typically represented as a vector:\n",
        "\n",
        "# ùë•\n",
        "# =[ ùë•1,ùë•2, ‚Ä¶,ùë•ùëõ]‚ä§x=[x1,x2,‚Ä¶,x n] ‚ä§\n",
        "\n",
        "# where\n",
        "# ùë•\n",
        "# ùëñ\n",
        "# x\n",
        "# i\n",
        "# ‚Äã\n",
        "#   are the features of the input data.\n",
        "\n",
        "# (b) Weights and Biases:\n",
        "# Each connection between neurons has an associated weight, and each neuron has a bias term. For a single layer:\n",
        "\n",
        "# ùëß\n",
        "# =\n",
        "# ùëä\n",
        "# ‚ãÖ\n",
        "# ùë•\n",
        "# +\n",
        "# ùëè\n",
        "# z=W‚ãÖx+b\n",
        "# ùëä\n",
        "# W: Weight matrix (dimensions depend on the layer sizes).\n",
        "# ùëè\n",
        "# b: Bias vector.\n",
        "# (c) Activation Functions:\n",
        "# After computing the linear combination\n",
        "# ùëß\n",
        "# z, a non-linear activation function\n",
        "# ùëì\n",
        "# f is applied element-wise:\n",
        "\n",
        "# ùëé\n",
        "# =\n",
        "# ùëì\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# a=f(z)\n",
        "# Common activation functions include:\n",
        "\n",
        "# Sigmoid:\n",
        "# ùëì\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# 1\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùëß\n",
        "# f(z)=\n",
        "# 1+e\n",
        "# ‚àíz\n",
        "\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# ReLU:\n",
        "# ùëì\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# ‚Å°\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# ùëß\n",
        "# )\n",
        "# f(z)=max(0,z)\n",
        "# Tanh:\n",
        "# ùëì\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# =\n",
        "# ùëí\n",
        "# ùëß\n",
        "# ‚àí\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùëß\n",
        "# ùëí\n",
        "# ùëß\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùëß\n",
        "# f(z)=\n",
        "# e\n",
        "# z\n",
        "#  +e\n",
        "# ‚àíz\n",
        "\n",
        "# e\n",
        "# z\n",
        "#  ‚àíe\n",
        "# ‚àíz\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# (d) Feedforward Process:\n",
        "# For a multi-layer neural network, the output of one layer serves as the input to the next:\n",
        "\n",
        "# ùëé\n",
        "# (\n",
        "# ùëô\n",
        "# +\n",
        "# 1\n",
        "# )\n",
        "# =\n",
        "# ùëì\n",
        "# (\n",
        "# ùëä\n",
        "# (\n",
        "# ùëô\n",
        "# )\n",
        "# ‚ãÖ\n",
        "# ùëé\n",
        "# (\n",
        "# ùëô\n",
        "# )\n",
        "# +\n",
        "# ùëè\n",
        "# (\n",
        "# ùëô\n",
        "# )\n",
        "# )\n",
        "# a\n",
        "# (l+1)\n",
        "#  =f(W\n",
        "# (l)\n",
        "#  ‚ãÖa\n",
        "# (l)\n",
        "#  +b\n",
        "# (l)\n",
        "#  )\n",
        "# Here,\n",
        "# ùëô\n",
        "# l indexes the layer.\n",
        "\n",
        "# (e) Loss Function:\n",
        "# The network's predictions are compared to the true outputs using a loss function\n",
        "# ùêø\n",
        "# L:\n",
        "\n",
        "# ùêø\n",
        "# (\n",
        "# ùë¶\n",
        "# ,\n",
        "# ùë¶\n",
        "# ^\n",
        "# )\n",
        "# L(y,\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Example loss functions: Mean Squared Error (MSE), Cross-Entropy Loss.\n",
        "# (f) Backpropagation:\n",
        "# Using the chain rule of calculus, the gradients of the loss function with respect to weights and biases are computed:\n",
        "\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùëä\n",
        "# ,\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùëè\n",
        "# ‚àÇW\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# ‚àÇb\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# These gradients guide the updates to the parameters.\n",
        "\n",
        "# (g) Optimization:\n",
        "# Weights and biases are updated iteratively using optimization algorithms like Gradient Descent:\n",
        "\n",
        "# ùëä\n",
        "# ‚Üê\n",
        "# ùëä\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùëä\n",
        "# W‚ÜêW‚àíŒ∑\n",
        "# ‚àÇW\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# where\n",
        "# ùúÇ\n",
        "# Œ∑ is the learning rate.\n",
        "\n",
        "# 3. Graph Representation:\n",
        "# A neural network can also be viewed as a computational graph:\n",
        "\n",
        "# Nodes represent mathematical operations (e.g., addition, multiplication, activation functions).\n",
        "# Edges represent data flow (e.g., inputs, intermediate values).\n",
        "# 4. Probabilistic Interpretation:\n",
        "# In some neural networks (e.g., Bayesian neural networks), the weights and outputs are treated as probabilistic variables, linking neural networks to probability theory."
      ],
      "metadata": {
        "id": "wUIqNkO8_lIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.4 What is an activation function, and why is it essential in neural"
      ],
      "metadata": {
        "id": "lCGnztIvBAbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is an Activation Function?\n",
        "# An activation function in a neural network determines whether a neuron should be activated or not by transforming the weighted sum of its inputs into an output signal. It introduces non-linearity into the network, enabling it to learn complex patterns and relationships in the data.\n",
        "\n",
        "# Why is it Essential in Neural Networks?\n",
        "# Introduces Non-linearity:\n",
        "\n",
        "# Without activation functions, the neural network behaves like a linear model, regardless of its depth. Linear transformations alone cannot model complex patterns.\n",
        "# Activation functions allow the network to approximate non-linear mappings, essential for solving real-world problems like image recognition and natural language processing.\n",
        "# Enables Learning of Complex Features:\n",
        "\n",
        "# Different activation functions capture various features from data. For example, ReLU (Rectified Linear Unit) helps in handling large models efficiently, while functions like sigmoid or tanh can be used for probabilities or normalized outputs.\n",
        "# Controls Output Range:\n",
        "\n",
        "# Some activation functions, like sigmoid (0 to 1) or tanh (-1 to 1), normalize outputs, making them suitable for certain tasks, such as binary classification or intermediate layers.\n",
        "# Avoids Saturation:\n",
        "\n",
        "# Modern activation functions like ReLU avoid issues like vanishing gradients that older functions (e.g., sigmoid, tanh) often face. This improves gradient-based optimization and speeds up learning.\n",
        "# Commonly Used Activation Functions:\n",
        "# Sigmoid:\n",
        "\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# 1\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# œÉ(x)=\n",
        "# 1+e\n",
        "# ‚àíx\n",
        "\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# Outputs values in the range (0, 1).\n",
        "# Often used in binary classification problems.\n",
        "# Tanh:\n",
        "\n",
        "# tanh\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùëí\n",
        "# ùë•\n",
        "# ‚àí\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# ùëí\n",
        "# ùë•\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# tanh(x)=\n",
        "# e\n",
        "# x\n",
        "#  +e\n",
        "# ‚àíx\n",
        "\n",
        "# e\n",
        "# x\n",
        "#  ‚àíe\n",
        "# ‚àíx\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# Outputs values in the range (-1, 1).\n",
        "# Preferred over sigmoid when zero-centered outputs are beneficial.\n",
        "# ReLU (Rectified Linear Unit):\n",
        "\n",
        "# ReLU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# ‚Å°\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# ùë•\n",
        "# )\n",
        "# ReLU(x)=max(0,x)\n",
        "# Introduces sparsity by outputting zero for negative values.\n",
        "# Popular for deep networks due to its simplicity and computational efficiency.\n",
        "# Leaky ReLU:\n",
        "\n",
        "# Leaky¬†ReLU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùë•\n",
        "# Leaky¬†ReLU(x)=x if\n",
        "# ùë•\n",
        "# >\n",
        "# 0\n",
        "# x>0, else\n",
        "# ùõº\n",
        "# ùë•\n",
        "# Œ±x (where\n",
        "# ùõº\n",
        "# Œ± is a small constant, e.g., 0.01).\n",
        "# Addresses ReLU‚Äôs \"dying neuron\" problem by allowing a small gradient for negative inputs.\n",
        "# Softmax:\n",
        "\n",
        "# Used in the output layer for multi-class classification problems.\n",
        "# Converts raw scores into probabilities that sum to 1."
      ],
      "metadata": {
        "id": "KGcysYSMrOxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.5 Could you list some common activation functions used in neural networks"
      ],
      "metadata": {
        "id": "wLjoiJSCrkNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sigmoid Function\n",
        "# Formula:\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# 1\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# œÉ(x)=\n",
        "# 1+e\n",
        "# ‚àíx\n",
        "\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# Range: (0, 1)\n",
        "# Characteristics:\n",
        "# Smooth, differentiable.\n",
        "# Good for probabilities in binary classification.\n",
        "# Can suffer from vanishing gradient problems in deep networks.\n",
        "# Use Case: Output layer for binary classification.\n",
        "# 2. Tanh (Hyperbolic Tangent)\n",
        "# Formula:\n",
        "# tanh\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùëí\n",
        "# ùë•\n",
        "# ‚àí\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# ùëí\n",
        "# ùë•\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# tanh(x)=\n",
        "# e\n",
        "# x\n",
        "#  +e\n",
        "# ‚àíx\n",
        "\n",
        "# e\n",
        "# x\n",
        "#  ‚àíe\n",
        "# ‚àíx\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# Range: (-1, 1)\n",
        "# Characteristics:\n",
        "# Zero-centered, which can help with faster convergence during training.\n",
        "# Suffers from vanishing gradients like sigmoid.\n",
        "# Use Case: Hidden layers in shallow networks.\n",
        "# 3. ReLU (Rectified Linear Unit)\n",
        "# Formula:\n",
        "# ReLU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# ‚Å°\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# ùë•\n",
        "# )\n",
        "# ReLU(x)=max(0,x)\n",
        "# Range: [0, ‚àû)\n",
        "# Characteristics:\n",
        "# Introduces sparsity by outputting zero for negative values.\n",
        "# Computationally efficient and widely used.\n",
        "# Can face the dying neuron problem (neurons stop updating for large negative inputs).\n",
        "# Use Case: Default activation for hidden layers in deep networks.\n",
        "# 4. Leaky ReLU\n",
        "# Formula:\n",
        "# Leaky¬†ReLU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# {\n",
        "# ùë•\n",
        "# if\n",
        "# ùë•\n",
        "# >\n",
        "# 0\n",
        "# ùõº\n",
        "# ùë•\n",
        "# if\n",
        "# ùë•\n",
        "# ‚â§\n",
        "# 0\n",
        "# Leaky¬†ReLU(x)={\n",
        "# x\n",
        "# Œ±x\n",
        "# ‚Äã\n",
        "\n",
        "# if¬†x>0\n",
        "# if¬†x‚â§0\n",
        "# ‚Äã\n",
        "#  , where\n",
        "# ùõº\n",
        "# Œ± (e.g., 0.01) is a small positive constant.\n",
        "# Range: (-‚àû, ‚àû)\n",
        "# Characteristics:\n",
        "# Allows a small gradient for negative inputs, mitigating the dying neuron problem.\n",
        "# Use Case: Hidden layers in deep networks with negative inputs.\n",
        "# 5. Parametric ReLU (PReLU)\n",
        "# Formula:\n",
        "# PReLU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# {\n",
        "# ùë•\n",
        "# if\n",
        "# ùë•\n",
        "# >\n",
        "# 0\n",
        "# ùõº\n",
        "# ùë•\n",
        "# if\n",
        "# ùë•\n",
        "# ‚â§\n",
        "# 0\n",
        "# PReLU(x)={\n",
        "# x\n",
        "# Œ±x‚Äã\n",
        "\n",
        "# if¬†x>0\n",
        "# if¬†x‚â§0 ‚Äã\n",
        "#  , where\n",
        "# ùõº\n",
        "# Œ± is learned during training.\n",
        "# Range: (-‚àû, ‚àû)\n",
        "# Characteristics:\n",
        "# Adaptable version of Leaky ReLU with trainable parameters.\n",
        "# Use Case: Hidden layers for networks requiring additional flexibility.\n",
        "# 6. Softmax\n",
        "# Formula:\n",
        "# Softmax\n",
        "# (\n",
        "# ùë•\n",
        "# ùëñ\n",
        "# )\n",
        "# =\n",
        "# ùëí\n",
        "# ùë•\n",
        "# ùëñ\n",
        "# ‚àë\n",
        "# ùëó\n",
        "# =\n",
        "# 1\n",
        "# ùëõ\n",
        "# ùëí\n",
        "# ùë•\n",
        "# ùëó\n",
        "# Softmax(x\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )=\n",
        "# ‚àë\n",
        "# j=1\n",
        "# n\n",
        "# ‚Äã\n",
        "#  e\n",
        "# x\n",
        "# j\n",
        "# ‚Äã\n",
        "\n",
        "\n",
        "# e\n",
        "# x\n",
        "# i\n",
        "# ‚Äã\n",
        "\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# Range: (0, 1), with outputs summing to 1.\n",
        "# Characteristics:\n",
        "# Converts raw scores into probabilities.\n",
        "# Ensures outputs are normalized for multi-class classification.\n",
        "# Use Case: Output layer in multi-class classification problems.\n",
        "# 7. Swish\n",
        "# Formula:\n",
        "# Swish\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùë•\n",
        "# ‚ãÖ\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# Swish(x)=x‚ãÖœÉ(x), where\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# œÉ(x) is the sigmoid function.\n",
        "# Range: (-‚àû, ‚àû)\n",
        "# Characteristics:\n",
        "# Smooth and non-monotonic.\n",
        "# Outperforms ReLU in some deep networks.\n",
        "# Use Case: Deep learning tasks requiring smooth gradients.\n",
        "# 8. GELU (Gaussian Error Linear Unit)\n",
        "# Formula:\n",
        "# GELU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùë•\n",
        "# ‚ãÖ\n",
        "# Œ¶\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# GELU(x)=x‚ãÖŒ¶(x), where\n",
        "# Œ¶\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# Œ¶(x) is the cumulative distribution function of a Gaussian.\n",
        "# Range: (-‚àû, ‚àû)\n",
        "# Characteristics:\n",
        "# Smooth approximation, combines features of ReLU and sigmoid.\n",
        "# Used in state-of-the-art models like BERT.\n",
        "# Use Case: Transformer-based architectures and NLP tasks.\n",
        "# 9. ELU (Exponential Linear Unit)\n",
        "# Formula:\n",
        "# ELU\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# {\n",
        "# ùë•\n",
        "# if\n",
        "# ùë•\n",
        "# >\n",
        "# 0\n",
        "# ùõº\n",
        "# (\n",
        "# ùëí\n",
        "# ùë•\n",
        "# ‚àí\n",
        "# 1\n",
        "# )\n",
        "# if\n",
        "# ùë•\n",
        "# ‚â§\n",
        "# 0\n",
        "# ELU(x)={\n",
        "# x\n",
        "# Œ±(e\n",
        "# x\n",
        "#  ‚àí1)\n",
        "# ‚Äã\n",
        "\n",
        "# if¬†x>0\n",
        "# if¬†x‚â§0\n",
        "# ‚Äã\n",
        "#  , where\n",
        "# ùõº\n",
        "# >\n",
        "# 0\n",
        "# Œ±>0.\n",
        "# Range: (-Œ±, ‚àû)\n",
        "# Characteristics:\n",
        "# Smooth and zero-centered.\n",
        "# Helps avoid dead neurons while reducing bias shifts.\n",
        "# Use Case: Deep networks requiring smooth activation.\n",
        "# 10. Maxout\n",
        "# Formula:\n",
        "# Maxout\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë§\n",
        "# 1\n",
        "# ùëá\n",
        "# ùë•\n",
        "# +\n",
        "# ùëè\n",
        "# 1\n",
        "# ,\n",
        "# ùë§\n",
        "# 2\n",
        "# ùëá\n",
        "# ùë•\n",
        "# +\n",
        "# ùëè\n",
        "# 2\n",
        "# )\n",
        "# Maxout(x)=max(w\n",
        "# 1\n",
        "# T\n",
        "# ‚Äã\n",
        "#  x+b\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  ,w\n",
        "# 2\n",
        "# T\n",
        "# ‚Äã\n",
        "#  x+b\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Range: (-‚àû, ‚àû)\n",
        "# Characteristics:\n",
        "# Generalizes ReLU and Leaky ReLU.\n",
        "# Increases parameter count, requiring more memory.\n",
        "# Use Case: Networks where learning a piecewise linear function is advantageous."
      ],
      "metadata": {
        "id": "KKN7bUSqrz0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.6 What is a multilayer neural network"
      ],
      "metadata": {
        "id": "OfnfDjbisrh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a Multilayer Neural Network?\n",
        "# A multilayer neural network, also known as a multilayer perceptron (MLP), is a type of artificial neural network consisting of multiple layers of neurons organized sequentially. It extends the basic single-layer perceptron by including one or more hidden layers between the input and output layers.\n",
        "\n",
        "# Key Components of a Multilayer Neural Network:\n",
        "# Input Layer:\n",
        "\n",
        "# Receives the input features of the data (e.g., pixels in an image, numerical data).\n",
        "# Each neuron in this layer corresponds to one feature in the input data.\n",
        "# Hidden Layers:\n",
        "\n",
        "# Composed of neurons that perform intermediate computations.\n",
        "# Each neuron processes the weighted sum of inputs from the previous layer and applies an activation function.\n",
        "# The number of hidden layers and neurons per layer determines the depth and capacity of the network.\n",
        "# Output Layer:\n",
        "\n",
        "# Produces the final output, such as probabilities (for classification) or a numerical value (for regression).\n",
        "# The number of neurons in this layer corresponds to the desired output dimensionality.\n",
        "# Weights and Biases:\n",
        "\n",
        "# Each connection between neurons has an associated weight, which determines the strength and direction of influence.\n",
        "# Neurons also have a bias, which allows the model to fit data that do not pass through the origin.\n",
        "# Activation Functions:\n",
        "\n",
        "# Introduce non-linearity into the network to allow it to learn complex patterns.\n",
        "# Characteristics of a Multilayer Neural Network:\n",
        "# Fully Connected: In a typical MLP, every neuron in one layer is connected to every neuron in the next layer (hence also called a fully connected network).\n",
        "\n",
        "# Feedforward Structure: Information flows from the input layer to the output layer without cycles.\n",
        "\n",
        "# Non-linearity: Activation functions enable the network to approximate non-linear mappings.\n",
        "\n",
        "# Working of a Multilayer Neural Network:\n",
        "# Forward Propagation:\n",
        "\n",
        "# Input data is passed through the network layer by layer.\n",
        "# Each neuron computes a weighted sum of inputs, applies an activation function, and passes the result to the next layer.\n",
        "# Loss Calculation:\n",
        "\n",
        "# The network's output is compared to the actual target values to calculate a loss (error).\n",
        "# Backward Propagation:\n",
        "\n",
        "# The network adjusts its weights and biases using the gradient of the loss function with respect to each parameter.\n",
        "# This is typically done using the backpropagation algorithm and an optimization method like stochastic gradient descent (SGD) or Adam.\n",
        "# Training:\n",
        "\n",
        "# The forward and backward propagation steps are repeated iteratively on the training dataset to minimize the loss.\n",
        "# Advantages of Multilayer Neural Networks:\n",
        "# Ability to Model Complex Patterns:\n",
        "\n",
        "# The inclusion of hidden layers allows MLPs to approximate any continuous function, making them suitable for tasks involving non-linear relationships.\n",
        "# Versatility:\n",
        "\n",
        "# Can be applied to a wide range of problems, including regression, classification, and time-series forecasting.\n",
        "# Scalability:\n",
        "\n",
        "# The architecture can be scaled by increasing the number of layers and neurons, allowing for more powerful models.\n",
        "# Disadvantages:\n",
        "# Overfitting:\n",
        "\n",
        "# Complex networks can overfit to the training data, requiring regularization techniques like dropout or weight decay.\n",
        "# Computational Cost:\n",
        "\n",
        "# Training deep networks requires significant computational resources and time.\n",
        "# Vanishing/Exploding Gradients:\n",
        "\n",
        "# Training very deep networks can be challenging due to issues with gradient propagation, although modern techniques (e.g., ReLU, batch normalization) mitigate this.\n",
        "# Applications:\n",
        "# Image recognition (e.g., handwritten digit recognition with MNIST dataset)\n",
        "# Natural language processing (e.g., sentiment analysis, translation)\n",
        "# Regression tasks (e.g., stock price prediction)\n",
        "# Classification problems (e.g., spam detection)"
      ],
      "metadata": {
        "id": "dEtsm3rFt8Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.7 What is a loss function, and why is it crucial for neural network training?"
      ],
      "metadata": {
        "id": "NyJc_wNtt9eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A loss function (also known as a cost function or objective function) is a mathematical function that measures the difference between the predicted output of a neural network and the actual target or ground truth values. During the training of a neural network, the goal is to minimize this loss function, effectively improving the accuracy of the network's predictions.\n",
        "\n",
        "# Importance of a Loss Function in Neural Network Training:\n",
        "# Guiding Optimization: The loss function serves as the metric that the neural network uses to understand how well it is performing. The lower the value of the loss function, the better the network‚Äôs predictions are. This enables the training algorithm (typically using methods like gradient descent) to adjust the network's weights to minimize the loss and improve prediction accuracy.\n",
        "\n",
        "# Feedback for Learning: The loss provides feedback to the model during training. By computing the loss, the model can determine how much its predictions deviate from the actual results and update the weights to reduce this error. The goal is to make the neural network learn the optimal parameters (weights) that minimize the loss over time.\n",
        "\n",
        "# Enabling Gradient Descent: A loss function is essential for the backpropagation process in neural networks. After each forward pass, the loss function computes the error, and the gradients of this error are used during backpropagation to update the model‚Äôs weights. Without a loss function, the model wouldn‚Äôt know how to adjust its weights to improve performance.\n",
        "\n",
        "# Type of Problems Solved: The specific form of the loss function depends on the type of problem being solved. For example:\n",
        "\n",
        "# For regression tasks, where the goal is to predict continuous values, Mean Squared Error (MSE) is often used.\n",
        "# For classification tasks, where the goal is to categorize inputs into discrete classes, Cross-Entropy Loss (or log loss) is commonly used."
      ],
      "metadata": {
        "id": "8JdphC1S1iES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.8 What are some common types of loss functions?"
      ],
      "metadata": {
        "id": "Xq6ZBbwQVOMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mean Squared Error (MSE) Loss\n",
        "# Use case: Typically used for regression tasks.\n",
        "\n",
        "# Definition: It calculates the average squared difference between the predicted values and the actual values.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# MSE\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# (\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# 2\n",
        "# MSE=\n",
        "# N\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  (y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )\n",
        "# 2\n",
        "\n",
        "# Where:\n",
        "\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# y\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the true value,\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the predicted value,\n",
        "# ùëÅ\n",
        "# N is the number of samples.\n",
        "# Purpose: MSE penalizes large errors more heavily due to the squaring of the differences, making it sensitive to outliers.\n",
        "\n",
        "# 2. Mean Absolute Error (MAE) Loss\n",
        "# Use case: Used for regression tasks when you want to avoid the sensitivity to outliers that MSE causes.\n",
        "# Definition: It calculates the average of the absolute differences between the predicted and actual values.\n",
        "# Formula:\n",
        "# MAE\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ‚à£\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# ‚à£\n",
        "# MAE=\n",
        "# N\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  ‚à£y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚à£\n",
        "# Purpose: MAE gives a linear error penalty, making it more robust to outliers compared to MSE.\n",
        "# 3. Cross-Entropy Loss (Log Loss)\n",
        "# Use case: Typically used for classification tasks, especially binary and multi-class classification problems.\n",
        "\n",
        "# Definition: Cross-Entropy loss measures the difference between two probability distributions, the predicted probability distribution and the true distribution (which is usually a one-hot encoded vector).\n",
        "\n",
        "# Formula (binary classification):\n",
        "\n",
        "# Binary¬†Cross-Entropy\n",
        "# =\n",
        "# ‚àí\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# (\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# log\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# )\n",
        "# log\n",
        "# ‚Å°\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# )\n",
        "# Binary¬†Cross-Entropy=‚àí\n",
        "# N\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  (y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  log(\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )+(1‚àíy\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )log(1‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ))\n",
        "# Where:\n",
        "\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# y\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the true label (0 or 1),\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the predicted probability for class 1.\n",
        "# Formula (multi-class classification):\n",
        "\n",
        "# Categorical¬†Cross-Entropy\n",
        "# =\n",
        "# ‚àí\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# log\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# Categorical¬†Cross-Entropy=‚àí\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  log(\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Where\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# y\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the true class (in a one-hot encoded form) and\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the predicted probability of the class.\n",
        "\n",
        "# Purpose: Cross-Entropy Loss is particularly useful for classification because it quantifies the difference between the true distribution and predicted probabilities, encouraging the network to output probabilities that match the true class distribution.\n",
        "\n",
        "# 4. Hinge Loss\n",
        "# Use case: Primarily used for Support Vector Machines (SVMs) but can also be used in neural networks for binary classification tasks.\n",
        "\n",
        "# Definition: Hinge loss is designed to maximize the margin between classes, encouraging correct classification with a margin of at least 1.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# Hinge¬†Loss\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# max\n",
        "# ‚Å°\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# Hinge¬†Loss=\n",
        "# N\n",
        "# 1\n",
        "# ‚Äã\n",
        "\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  max(0,1‚àíy\n",
        "# i\n",
        "# ‚Äã\n",
        "\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Where:\n",
        "\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# y\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the true label (\n",
        "# +\n",
        "# 1\n",
        "# +1 or\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí1),\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the predicted value.\n",
        "# Purpose: It is used when the output is expected to be either +1 or -1 (e.g., in binary classification) and encourages the model to correctly classify examples with a margin.\n",
        "\n",
        "# 5. Huber Loss\n",
        "# Use case: Used for regression tasks, especially when you want to combine the benefits of both MSE and MAE.\n",
        "\n",
        "# Definition: Huber loss is less sensitive to outliers than MSE but more sensitive than MAE. It behaves like MSE when the error is small and like MAE when the error is large.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# Huber¬†Loss\n",
        "# =\n",
        "# {\n",
        "# 1\n",
        "# 2\n",
        "# (\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# )\n",
        "# 2\n",
        "# for\n",
        "# ‚à£\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# ‚à£\n",
        "# ‚â§\n",
        "# ùõø\n",
        "# ùõø\n",
        "# ‚à£\n",
        "# ùë¶\n",
        "# ùëñ\n",
        "# ‚àí\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# ‚à£\n",
        "# ‚àí\n",
        "# 1\n",
        "# 2\n",
        "# ùõø\n",
        "# 2\n",
        "# otherwise\n",
        "# Huber¬†Loss={\n",
        "# 2\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  (y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  )\n",
        "# 2\n",
        "\n",
        "# Œ¥‚à£y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚à£‚àí\n",
        "# 2\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  Œ¥\n",
        "# 2\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# for¬†‚à£y\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  ‚à£‚â§Œ¥\n",
        "# otherwise\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùõø\n",
        "# Œ¥ is a threshold parameter.\n",
        "\n",
        "# Purpose: The Huber loss is a compromise between MSE and MAE, offering robust handling of outliers while retaining smooth gradients.\n",
        "\n",
        "# 6. Kullback-Leibler (KL) Divergence\n",
        "# Use case: Used for measuring how one probability distribution diverges from a second, expected probability distribution. It is common in tasks involving generative models, like variational autoencoders.\n",
        "\n",
        "# Definition: KL divergence quantifies the difference between two probability distributions.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# ùê∑\n",
        "# KL\n",
        "# (\n",
        "# ùëÉ\n",
        "# ‚à•\n",
        "# ùëÑ\n",
        "# )\n",
        "# =\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# ùëÉ\n",
        "# (\n",
        "# ùëñ\n",
        "# )\n",
        "# log\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùëÉ\n",
        "# (\n",
        "# ùëñ\n",
        "# )\n",
        "# ùëÑ\n",
        "# (\n",
        "# ùëñ\n",
        "# )\n",
        "# )\n",
        "# D\n",
        "# KL\n",
        "# ‚Äã\n",
        "#  (P‚à•Q)=\n",
        "# i\n",
        "# ‚àë\n",
        "# ‚Äã\n",
        "#  P(i)log(\n",
        "# Q(i)\n",
        "# P(i)\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Where:\n",
        "\n",
        "# ùëÉ\n",
        "# (\n",
        "# ùëñ\n",
        "# )\n",
        "# P(i) is the true probability distribution,\n",
        "# ùëÑ\n",
        "# (\n",
        "# ùëñ\n",
        "# )\n",
        "# Q(i) is the predicted probability distribution.\n",
        "# Purpose: It measures how much one distribution differs from a second reference distribution, used in tasks like model regularization or comparing predicted probability distributions to the actual ones.\n",
        "\n",
        "# 7. Cosine Similarity Loss\n",
        "# Use case: Used when you need to measure the angle between two vectors, commonly applied in tasks like text similarity or recommendations.\n",
        "\n",
        "# Definition: Measures the cosine of the angle between the predicted vector and the true vector. The loss function minimizes the angle between the two vectors, ensuring they are more similar.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# Cosine¬†Similarity\n",
        "# =\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùê¥\n",
        "# ‚ãÖ\n",
        "# ùêµ\n",
        "# ‚à•\n",
        "# ùê¥\n",
        "# ‚à•\n",
        "# ‚à•\n",
        "# ùêµ\n",
        "# ‚à•\n",
        "# Cosine¬†Similarity=1‚àí\n",
        "# ‚à•A‚à•‚à•B‚à•\n",
        "# A‚ãÖB\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "\n",
        "# ùê¥\n",
        "# A and\n",
        "# ùêµ\n",
        "# B are the two vectors (e.g., the true label and the predicted output).\n",
        "# Purpose: Cosine similarity is useful in tasks like text classification, where the model outputs vectors of features (e.g., word embeddings) instead of discrete classes.\n",
        "\n",
        "# 8. Sparse Categorical Cross-Entropy Loss\n",
        "# Use case: Used in classification tasks when the true labels are provided as integers instead of one-hot encoded vectors (common in multi-class classification).\n",
        "\n",
        "# Definition: This loss function is a variant of the categorical cross-entropy loss, but it accepts integer labels instead of one-hot encoded vectors.\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# Sparse¬†Categorical¬†Cross-Entropy\n",
        "# =\n",
        "# ‚àí\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# =\n",
        "# 1\n",
        "# ùëÅ\n",
        "# log\n",
        "# ‚Å°\n",
        "# (\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# [\n",
        "# ùë¶\n",
        "# ]\n",
        "# )\n",
        "# Sparse¬†Categorical¬†Cross-Entropy=‚àí\n",
        "# i=1\n",
        "# ‚àë\n",
        "# N\n",
        "# ‚Äã\n",
        "#  log(\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#  [y])\n",
        "# Where\n",
        "# ùë¶\n",
        "# ^\n",
        "# ùëñ\n",
        "# y\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# i\n",
        "# ‚Äã\n",
        "#   is the predicted probability distribution, and\n",
        "# ùë¶\n",
        "# y is the integer label.\n",
        "\n",
        "# Purpose: It simplifies tasks where one-hot encoding is unnecessary, especially in large-class classification problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "YVpvwN74WT6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.9 How does a neural network learn?"
      ],
      "metadata": {
        "id": "ceBMa6sdadU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A neural network learns through a process called training, which involves adjusting its internal parameters (weights and biases) based on the data it receives. The goal of training is to minimize the difference between the predicted outputs and the actual target values, which is typically done using a loss function and an optimization algorithm. Here's an overview of how a neural network learns:\n",
        "\n",
        "# 1. Forward Propagation\n",
        "# The first step in the learning process is forward propagation, where input data is passed through the network.\n",
        "# Each layer in the neural network performs a mathematical operation on the input data, typically a linear transformation (weight multiplication and bias addition) followed by a non-linear activation function.\n",
        "# The input is processed through the layers, and the network produces an output (prediction).\n",
        "# 2. Loss Calculation\n",
        "# After the forward pass, the network compares its predicted output to the true target (actual values) using a loss function (e.g., Mean Squared Error, Cross-Entropy).\n",
        "# The loss function quantifies the error or difference between the predicted and actual values. The smaller the loss, the better the network's performance.\n",
        "# 3. Backpropagation\n",
        "# Backpropagation is the key algorithm for learning in neural networks. It uses the chain rule of calculus to compute the gradients of the loss function with respect to each weight in the network.\n",
        "# During backpropagation, the error (loss) is propagated backward from the output layer to the input layer. The network computes how much each weight in the network contributed to the error.\n",
        "# This allows the network to know which weights to adjust and by how much to minimize the loss.\n",
        "# 4. Gradient Descent and Weight Update\n",
        "# Once the gradients are computed, the weights are updated using an optimization algorithm, typically Gradient Descent or its variants (e.g., Stochastic Gradient Descent, Adam).\n",
        "# The goal of Gradient Descent is to find the minimum of the loss function by adjusting the weights in the direction that reduces the loss. The update rule typically looks like:\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# w=w‚àíŒ∑‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "# ùë§\n",
        "# w is the weight,\n",
        "# ùúÇ\n",
        "# Œ∑ is the learning rate (how big each step is),\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient of the loss function with respect to the weight.\n",
        "# 5. Iteration and Epochs\n",
        "# This process of forward propagation, loss calculation, backpropagation, and weight update is repeated over many iterations (also called batches) and over multiple epochs (passes through the entire training dataset).\n",
        "# During each epoch, the neural network gradually improves its predictions by continuously adjusting its weights based on the feedback (error) it receives.\n",
        "# 6. Convergence\n",
        "# Over time, as the network sees more data and updates its weights, the loss typically decreases, meaning the network‚Äôs predictions are becoming more accurate.\n",
        "# The training continues until the network converges (i.e., the loss stops significantly improving or reaches an acceptable value) or until a predefined number of epochs is reached.\n",
        "# Key Components in Neural Network Learning:\n",
        "# Weights and Biases: These are the parameters that the network learns. Weights control the strength of connections between neurons, while biases allow the network to shift its outputs.\n",
        "\n",
        "# Activation Function: Non-linear functions (like ReLU, Sigmoid, Tanh) applied after each layer‚Äôs weighted sum. They allow the network to model complex relationships and introduce non-linearity.\n",
        "\n",
        "# Loss Function: A function that calculates the error between the network's prediction and the actual target. The goal is to minimize this loss.\n",
        "\n",
        "# Optimizer: The algorithm (e.g., Gradient Descent) used to adjust the weights based on the gradients computed during backpropagation. It helps the network learn by iteratively reducing the loss.\n",
        "\n",
        "# Learning Rate: A hyperparameter that controls the size of the steps taken during weight updates. If it‚Äôs too large, the network might overshoot the optimal solution; if it‚Äôs too small, learning can be very slow."
      ],
      "metadata": {
        "id": "tg3IMYlCbGZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.10 What is an optimizer in neural networks, and why is it necessary?"
      ],
      "metadata": {
        "id": "00U4S_qLbafm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why is an Optimizer Necessary?\n",
        "# Adjusting Model Parameters: During training, a neural network‚Äôs parameters (weights and biases) are initialized with random values. To make the network perform better, these parameters must be adjusted based on the errors made by the network (i.e., the difference between the predicted and actual outputs). The optimizer is responsible for these adjustments, helping the model \"learn\" and improve its accuracy.\n",
        "\n",
        "# Minimizing the Loss Function: The optimizer uses gradient information (from backpropagation) to minimize the loss function, which measures how far the model‚Äôs predictions are from the true values. By minimizing the loss, the optimizer ensures the network becomes more accurate as training progresses.\n",
        "\n",
        "# Efficient Learning: The optimizer determines how quickly or slowly the weights should be updated. This is important because the learning process can be slow if updates are too small, or unstable if they are too large. An optimizer helps balance this, ensuring the model converges to a good solution effectively.\n",
        "\n",
        "# Speeding Up Convergence: Different optimizers have varying strategies for updating the model‚Äôs parameters. Some can converge to a solution more quickly by adjusting the learning rate dynamically, incorporating momentum, or using adaptive learning methods. The choice of optimizer can greatly impact how fast the model learns and whether it converges to the best possible solution.\n",
        "\n",
        "# How Does an Optimizer Work?\n",
        "# Optimizers work based on the gradients calculated during backpropagation. The process generally involves the following steps:\n",
        "\n",
        "# Gradient Calculation: Backpropagation computes the gradient of the loss function with respect to each weight in the network. This gradient indicates the direction in which the weights need to be adjusted in order to minimize the loss.\n",
        "\n",
        "# Weight Update: The optimizer uses the computed gradients to update the weights in a way that reduces the loss. This is done iteratively across multiple training steps (epochs) until the model converges.\n",
        "\n",
        "# Learning Rate: The optimizer often includes a learning rate, which controls how large each weight update should be. If the learning rate is too high, the optimizer might overshoot the optimal solution. If it‚Äôs too low, the model might take too long to converge.\n",
        "\n",
        "# Common Types of Optimizers\n",
        "# Gradient Descent (GD):\n",
        "\n",
        "# Description: The simplest optimizer, where weights are updated in the opposite direction of the gradient, scaled by the learning rate.\n",
        "# Formula:\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# w=w‚àíŒ∑‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "# ùë§\n",
        "# w is the weight,\n",
        "# ùúÇ\n",
        "# Œ∑ is the learning rate,\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient of the loss function with respect to\n",
        "# ùë§\n",
        "# w.\n",
        "# Types:\n",
        "# Batch Gradient Descent: Computes gradients using the entire dataset.\n",
        "# Stochastic Gradient Descent (SGD): Computes gradients using one training sample at a time.\n",
        "# Mini-batch Gradient Descent: A compromise between batch and stochastic, using a small batch of samples to compute gradients.\n",
        "# Stochastic Gradient Descent (SGD):\n",
        "\n",
        "# Description: A variant of gradient descent where the weights are updated based on a single sample or a small subset of the data (mini-batch) at a time.\n",
        "# Advantage: Faster updates, as it doesn‚Äôt need to compute gradients over the entire dataset before updating weights. However, the path to convergence is more erratic.\n",
        "# Disadvantage: Can lead to noisy updates, and might not always converge smoothly.\n",
        "# Momentum:\n",
        "\n",
        "# Description: Momentum builds on SGD by adding a \"velocity\" term, which helps the optimizer keep moving in the same direction for several steps (helps smooth out oscillations).\n",
        "# Formula:\n",
        "# ùë£\n",
        "# =\n",
        "# ùõΩ\n",
        "# ‚ãÖ\n",
        "# ùë£\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# )\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# v=Œ≤‚ãÖv+(1‚àíŒ≤)‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ùë£\n",
        "# w=w‚àíŒ∑‚ãÖv\n",
        "# Where:\n",
        "# ùë£\n",
        "# v is the velocity,\n",
        "# ùõΩ\n",
        "# Œ≤ is the momentum term (typically close to 1).\n",
        "# Advantage: Helps accelerate gradient descent, especially in regions where the gradient is small or noisy.\n",
        "# AdaGrad (Adaptive Gradient Algorithm):\n",
        "\n",
        "# Description: AdaGrad adapts the learning rate for each parameter by scaling it inversely with the square root of the sum of all historical squared gradients.\n",
        "# Formula:\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùê∫\n",
        "# ùë°\n",
        "# +\n",
        "# ùúñ\n",
        "# ‚ãÖ\n",
        "# ùëî\n",
        "# ùë°\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# G\n",
        "# t\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# ‚Äã\n",
        "\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "#  ‚ãÖg\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "# ùê∫\n",
        "# ùë°\n",
        "# G\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the sum of squared gradients up to time step\n",
        "# ùë°\n",
        "# t,\n",
        "# ùëî\n",
        "# ùë°\n",
        "# g\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the gradient at time step\n",
        "# ùë°\n",
        "# t,\n",
        "# ùúñ\n",
        "# œµ is a small constant to prevent division by zero.\n",
        "# Advantage: Helps with sparse data by providing larger updates for infrequent features.\n",
        "# Disadvantage: The learning rate can decrease too rapidly, making it difficult to converge in later stages.\n",
        "# RMSProp (Root Mean Square Propagation):\n",
        "\n",
        "# Description: RMSProp is an adaptive learning rate method that improves on AdaGrad by using a moving average of squared gradients to scale the learning rate.\n",
        "# Formula:\n",
        "# ùë£\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# 2\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤v\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤)g\n",
        "# t\n",
        "# 2\n",
        "# ‚Äã\n",
        "\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# +\n",
        "# ùúñ\n",
        "# ùëî\n",
        "# ùë°\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# ‚Äã\n",
        "\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "#  g\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "# ùë£\n",
        "# ùë°\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the moving average of squared gradients.\n",
        "# ùõΩ\n",
        "# Œ≤ controls the moving average‚Äôs weight.\n",
        "# Advantage: Helps avoid the diminishing learning rate problem seen in AdaGrad.\n",
        "# Disadvantage: Requires tuning of additional hyperparameters, like\n",
        "# ùõΩ\n",
        "# Œ≤.\n",
        "# Adam (Adaptive Moment Estimation):\n",
        "\n",
        "# Description: Adam combines the advantages of both Momentum and RMSProp. It uses both the first moment (mean of the gradients) and the second moment (variance of the gradients) to adapt the learning rate.\n",
        "# Formula:\n",
        "# ùëö\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# 1\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 1\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  m\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  )g\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ùë£\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# 2\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 2\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# 2\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  v\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  )g\n",
        "# t\n",
        "# 2\n",
        "# ‚Äã\n",
        "\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ^\n",
        "# =\n",
        "# ùëö\n",
        "# ùë°\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 1\n",
        "# ùë°\n",
        "# ,\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ^\n",
        "# =\n",
        "# ùë£\n",
        "# ùë°\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 2\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "#  =\n",
        "# 1‚àíŒ≤\n",
        "# 1\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "#  =\n",
        "# 1‚àíŒ≤\n",
        "# 2\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ^\n",
        "# +\n",
        "# ùúñ\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ^\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "# ùëö\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the moving average of gradients (first moment),\n",
        "# ùë£\n",
        "# ùë°\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the moving average of squared gradients (second moment),\n",
        "# ùõΩ\n",
        "# 1\n",
        "# Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#   and\n",
        "# ùõΩ\n",
        "# 2\n",
        "# Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#   are hyperparameters controlling the decay rates of the moving averages.\n",
        "# Advantage: Adam adapts the learning rate for each parameter and combines the benefits of momentum and RMSProp, making it one of the most popular optimizers in practice.\n",
        "# Disadvantage: It requires careful tuning of hyperparameters, particularly for\n",
        "# ùõΩ\n",
        "# 1\n",
        "# Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# ùõΩ\n",
        "# 2\n",
        "# Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  , and the learning rate."
      ],
      "metadata": {
        "id": "0EKkI6nIbn_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.11 Could you briefly describe some common optimizers?"
      ],
      "metadata": {
        "id": "X7pMjaqPcIDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gradient Descent (GD)\n",
        "# Description: The simplest optimizer, it updates weights by moving them in the direction of the negative gradient of the loss function.\n",
        "# Formula:\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# w=w‚àíŒ∑‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùúÇ\n",
        "# Œ∑ is the learning rate and\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient of the loss with respect to the weight.\n",
        "# Variants:\n",
        "# Batch Gradient Descent: Uses the entire dataset to compute gradients and update weights (slow for large datasets).\n",
        "# Stochastic Gradient Descent (SGD): Updates weights after each individual training example.\n",
        "# Mini-batch Gradient Descent: A compromise, using a small batch of training examples to compute gradients.\n",
        "# Pros: Simple and straightforward.\n",
        "# Cons: Slow convergence, especially for large datasets. May struggle with local minima.\n",
        "# 2. Stochastic Gradient Descent (SGD)\n",
        "# Description: A variant of gradient descent that updates weights after processing each training sample (stochastic means \"random\").\n",
        "# Formula:\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# w=w‚àíŒ∑‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient based on a single data point.\n",
        "# Pros: Faster updates, more frequent weight changes, and often helps escape local minima.\n",
        "# Cons: Noisy updates, which can make convergence less stable.\n",
        "# 3. Momentum\n",
        "# Description: An extension of SGD that uses a moving average of past gradients to smooth the updates and help accelerate convergence.\n",
        "# Formula:\n",
        "# ùë£\n",
        "# =\n",
        "# ùõΩ\n",
        "# ‚ãÖ\n",
        "# ùë£\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# )\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# v=Œ≤‚ãÖv+(1‚àíŒ≤)‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ùë£\n",
        "# w=w‚àíŒ∑‚ãÖv\n",
        "# Where\n",
        "# ùë£\n",
        "# v is the velocity (weighted average of previous gradients), and\n",
        "# ùõΩ\n",
        "# Œ≤ is the momentum term.\n",
        "# Pros: Accelerates convergence by reducing oscillations and smoothing updates.\n",
        "# Cons: Requires tuning of the momentum parameter\n",
        "# ùõΩ\n",
        "# Œ≤.\n",
        "# 4. AdaGrad (Adaptive Gradient Algorithm)\n",
        "# Description: An adaptive optimizer that adjusts the learning rate for each parameter, giving larger updates to sparse features and smaller updates to frequent ones.\n",
        "# Formula:\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùê∫\n",
        "# ùë°\n",
        "# +\n",
        "# ùúñ\n",
        "# ‚ãÖ\n",
        "# ùëî\n",
        "# ùë°\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# G\n",
        "# t\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# ‚Äã\n",
        "\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "#  ‚ãÖg\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùê∫\n",
        "# ùë°\n",
        "# G\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the sum of squared gradients up to time\n",
        "# ùë°\n",
        "# t,\n",
        "# ùëî\n",
        "# ùë°\n",
        "# g\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the gradient at time\n",
        "# ùë°\n",
        "# t, and\n",
        "# ùúñ\n",
        "# œµ is a small value to prevent division by zero.\n",
        "# Pros: Works well for sparse data and reduces the learning rate over time.\n",
        "# Cons: The learning rate can decrease too quickly, causing slow convergence in later stages.\n",
        "# 5. RMSProp (Root Mean Square Propagation)\n",
        "# Description: Similar to AdaGrad, but it uses a moving average of squared gradients to normalize the learning rate, helping to prevent the rapid decay of learning rates seen in AdaGrad.\n",
        "# Formula:\n",
        "# ùë£\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# 2\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤v\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤)g\n",
        "# t\n",
        "# 2\n",
        "# ‚Äã\n",
        "\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# +\n",
        "# ùúñ\n",
        "# ‚ãÖ\n",
        "# ùëî\n",
        "# ùë°\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# ‚Äã\n",
        "\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "#  ‚ãÖg\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùë£\n",
        "# ùë°\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#   is the moving average of squared gradients, and\n",
        "# ùõΩ\n",
        "# Œ≤ is the smoothing factor.\n",
        "# Pros: Prevents the learning rate from decaying too quickly (unlike AdaGrad).\n",
        "# Cons: Still requires hyperparameter tuning.\n",
        "# 6. Adam (Adaptive Moment Estimation)\n",
        "# Description: One of the most popular optimizers, Adam combines the benefits of both Momentum and RMSProp. It uses both first-order (mean of gradients) and second-order (variance of gradients) moments to adapt the learning rate.\n",
        "# Formula:\n",
        "# ùëö\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# 1\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 1\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  m\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  )g\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ùë£\n",
        "# ùë°\n",
        "# =\n",
        "# ùõΩ\n",
        "# 2\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 2\n",
        "# )\n",
        "# ùëî\n",
        "# ùë°\n",
        "# 2\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  v\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  +(1‚àíŒ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  )g\n",
        "# t\n",
        "# 2\n",
        "# ‚Äã\n",
        "\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ^\n",
        "# =\n",
        "# ùëö\n",
        "# ùë°\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 1\n",
        "# ùë°\n",
        "# ,\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ^\n",
        "# =\n",
        "# ùë£\n",
        "# ùë°\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùõΩ\n",
        "# 2\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "#  =\n",
        "# 1‚àíŒ≤\n",
        "# 1\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "#  =\n",
        "# 1‚àíŒ≤\n",
        "# 2\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ùë£\n",
        "# ùë°\n",
        "# ^\n",
        "# +\n",
        "# ùúñ\n",
        "# ‚ãÖ\n",
        "# ùëö\n",
        "# ùë°\n",
        "# ^\n",
        "# Œ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =Œ∏\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "#  ‚àí\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# Œ∑\n",
        "# ‚Äã\n",
        "#  ‚ãÖ\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ^\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùëö\n",
        "# ùë°\n",
        "# m\n",
        "# t\n",
        "# ‚Äã\n",
        "#   and\n",
        "# ùë£\n",
        "# ùë°\n",
        "# v\n",
        "# t\n",
        "# ‚Äã\n",
        "#   are the moving averages of the gradients and squared gradients, respectively, and\n",
        "# ùõΩ\n",
        "# 1\n",
        "# Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# ùõΩ\n",
        "# 2\n",
        "# Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#   are hyperparameters controlling their decay rates.\n",
        "# Pros: Very effective and widely used. Handles sparse gradients well and adapts the learning rate for each parameter.\n",
        "# Cons: Requires careful tuning of hyperparameters\n",
        "# ùõΩ\n",
        "# 1\n",
        "# Œ≤\n",
        "# 1\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# ùõΩ\n",
        "# 2\n",
        "# Œ≤\n",
        "# 2\n",
        "# ‚Äã\n",
        "#  , and learning rate.\n",
        "# 7. Nadam (Nesterov-accelerated Adaptive Moment Estimation)\n",
        "# Description: Combines Adam with Nesterov momentum, which computes the gradient based on the \"look-ahead\" of the parameter update.\n",
        "# Formula: Similar to Adam but includes the Nesterov correction in the momentum update step.\n",
        "# Pros: Can offer better performance than Adam on some tasks due to the \"look-ahead\" momentum.\n",
        "# Cons: More computationally expensive than Adam.\n",
        "# 8. Adadelta\n",
        "# Description: An extension of AdaGrad that reduces the aggressive, monotonically decreasing learning rate. Adadelta computes an exponentially decaying average of all past gradients and uses it to scale the learning rate.\n",
        "# Formula:\n",
        "# Œî\n",
        "# ùúÉ\n",
        "# ùë°\n",
        "# =\n",
        "# ‚àí\n",
        "# ùê∏\n",
        "# ^\n",
        "# [\n",
        "# Œî\n",
        "# ùúÉ\n",
        "# 2\n",
        "# ]\n",
        "# ùë°\n",
        "# ‚àí\n",
        "# 1\n",
        "# ùê∏\n",
        "# ^\n",
        "# [\n",
        "# ùëî\n",
        "# 2\n",
        "# ]\n",
        "# ùë°\n",
        "# +\n",
        "# ùúñ\n",
        "# ‚ãÖ\n",
        "# ùëî\n",
        "# ùë°\n",
        "# ŒîŒ∏\n",
        "# t\n",
        "# ‚Äã\n",
        "#  =‚àí\n",
        "# E\n",
        "# ^\n",
        "#  [g\n",
        "# 2\n",
        "#  ]\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  +œµ\n",
        "# E\n",
        "# ^\n",
        "#  [ŒîŒ∏\n",
        "# 2\n",
        "#  ]\n",
        "# t‚àí1\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ‚ãÖg\n",
        "# t\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùê∏\n",
        "# ^\n",
        "# [\n",
        "# Œî\n",
        "# ùúÉ\n",
        "# 2\n",
        "# ]\n",
        "# E\n",
        "# ^\n",
        "#  [ŒîŒ∏\n",
        "# 2\n",
        "#  ] is the decaying average of squared parameter updates and\n",
        "# ùê∏\n",
        "# ^\n",
        "# [\n",
        "# ùëî\n",
        "# 2\n",
        "# ]\n",
        "# E\n",
        "# ^\n",
        "#  [g\n",
        "# 2\n",
        "#  ] is the decaying average of squared gradients.\n",
        "# Pros: Adapts the learning rate while avoiding the vanishing learning rate issue of AdaGrad.\n",
        "# Cons: Still requires tuning of hyperparameters."
      ],
      "metadata": {
        "id": "cnLaZQlFcbQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.12 Can you explain forward and backward propagation in a neural network?"
      ],
      "metadata": {
        "id": "7q6LDPNRctj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Forward Propagation\n",
        "# Forward propagation is the process where input data is passed through the neural network to generate predictions or outputs. It involves the following steps:\n",
        "\n",
        "# Steps in Forward Propagation:\n",
        "# Input Layer: The process starts with the input layer, where data (e.g., images, text, numerical data) is fed into the network. The input layer passes this data to the next layer in the network.\n",
        "\n",
        "# Weighted Sum: Each neuron in the subsequent layers (hidden layers) receives a weighted sum of the outputs from the previous layer. The weight is a parameter of the model that determines the importance of the incoming information.\n",
        "\n",
        "# ùëß\n",
        "# =\n",
        "# ‚àë\n",
        "# ùëñ\n",
        "# ùë§\n",
        "# ùëñ\n",
        "# ùë•\n",
        "# ùëñ\n",
        "# +\n",
        "# ùëè\n",
        "# z=\n",
        "# i\n",
        "# ‚àë\n",
        "# ‚Äã\n",
        "#  w\n",
        "# i\n",
        "# ‚Äã\n",
        "#  x\n",
        "# i\n",
        "# ‚Äã\n",
        "#  +b\n",
        "# Where:\n",
        "\n",
        "# ùëß\n",
        "# z is the weighted sum,\n",
        "# ùë§\n",
        "# ùëñ\n",
        "# w\n",
        "# i\n",
        "# ‚Äã\n",
        "#   are the weights,\n",
        "# ùë•\n",
        "# ùëñ\n",
        "# x\n",
        "# i\n",
        "# ‚Äã\n",
        "#   are the inputs,\n",
        "# ùëè\n",
        "# b is the bias (optional, allows shifting the activation function).\n",
        "# Activation Function: After calculating the weighted sum, the neuron applies an activation function (like ReLU, Sigmoid, Tanh) to introduce non-linearity and determine the neuron's output. This is done for each neuron in every layer.\n",
        "\n",
        "# ùëé\n",
        "# =\n",
        "# activation\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# a=activation(z)\n",
        "# Where\n",
        "# ùëé\n",
        "# a is the output of the activation function.\n",
        "\n",
        "# Propagation Through Layers: The outputs of one layer (activations) become the inputs to the next layer. This process repeats until reaching the final layer (output layer).\n",
        "\n",
        "# Output Layer: The final layer produces the output of the network. For example, in a classification task, the output could be a probability distribution over the different classes (using a softmax activation), or a single continuous value in the case of regression (using a linear activation).\n",
        "\n",
        "# Example:\n",
        "# For a neural network that classifies images of cats and dogs:\n",
        "\n",
        "# The input data is an image represented as a vector.\n",
        "# The input layer passes the data through several hidden layers, where each neuron computes weighted sums and applies activation functions.\n",
        "# The final output layer may use a softmax activation to produce a probability distribution for the classes (cat vs. dog), like:\n",
        "# softmax\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# =\n",
        "# ùëí\n",
        "# ùëß\n",
        "# ‚àë\n",
        "# ùëí\n",
        "# ùëß\n",
        "# softmax(z)=\n",
        "# ‚àëe\n",
        "# z\n",
        "\n",
        "# e\n",
        "# z\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùëß\n",
        "# z is the output of the final layer before applying softmax.\n",
        "# 2. Backward Propagation (Backpropagation)\n",
        "# Backward propagation is the process used to train the neural network by adjusting the weights and biases based on the errors made by the model during forward propagation. This process aims to minimize the loss function (the error between predicted and actual values) by updating the weights and biases.\n",
        "\n",
        "# Steps in Backpropagation:\n",
        "# Compute the Loss: After forward propagation, the output is compared with the true target values (the actual labels). The loss function is used to compute the error between the predicted output and the true label. For example, in classification, we might use cross-entropy loss.\n",
        "\n",
        "# ùêø\n",
        "# =\n",
        "# Loss\n",
        "# (\n",
        "# ùë¶\n",
        "# true\n",
        "# ,\n",
        "# ùë¶\n",
        "# predicted\n",
        "# )\n",
        "# L=Loss(y\n",
        "# true\n",
        "# ‚Äã\n",
        "#  ,y\n",
        "# predicted\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Where\n",
        "# ùë¶\n",
        "# true\n",
        "# y\n",
        "# true\n",
        "# ‚Äã\n",
        "#   is the actual target and\n",
        "# ùë¶\n",
        "# predicted\n",
        "# y\n",
        "# predicted\n",
        "# ‚Äã\n",
        "#   is the output of the network.\n",
        "\n",
        "# Compute the Gradient of the Loss: We then calculate the gradient of the loss with respect to each weight in the network. This tells us how much each weight contributed to the error. The gradient is computed using the chain rule of calculus, which allows the error to be propagated backward from the output layer to the input layer.\n",
        "\n",
        "# The gradient is essentially the partial derivative of the loss function with respect to each weight:\n",
        "\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# =\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#  =\n",
        "# ‚àÇa\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#  ‚ãÖ\n",
        "# ‚àÇz\n",
        "# ‚àÇa\n",
        "# ‚Äã\n",
        "#  ‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇz\n",
        "# ‚Äã\n",
        "\n",
        "# Where:\n",
        "\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient of the loss with respect to the weight\n",
        "# ùë§\n",
        "# w,\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ‚àÇz\n",
        "# ‚àÇa\n",
        "# ‚Äã\n",
        "#   is the derivative of the activation function,\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇz\n",
        "# ‚Äã\n",
        "#   is the derivative of the weighted sum with respect to the weight.\n",
        "# Backpropagate the Error: Starting from the output layer, the error is propagated backward through each layer of the network, calculating gradients for each weight and bias. For each layer, we compute:\n",
        "\n",
        "# Gradient of the loss with respect to the activations (\n",
        "# ùëé\n",
        "# a) of the layer.\n",
        "# Gradient of the loss with respect to the weights and biases.\n",
        "# For the output layer, this typically involves the derivative of the loss function (e.g., softmax for classification or MSE for regression). For hidden layers, we use the chain rule to propagate the error backward through the activation functions.\n",
        "\n",
        "# Update Weights: Once we have computed the gradients of the loss with respect to the weights and biases, we update the weights using an optimization algorithm (like Gradient Descent or Adam).\n",
        "\n",
        "# ùë§\n",
        "# =\n",
        "# ùë§\n",
        "# ‚àí\n",
        "# ùúÇ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# w=w‚àíŒ∑‚ãÖ\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùúÇ\n",
        "# Œ∑ is the learning rate, and\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ‚àÇw\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#   is the gradient of the loss with respect to the weight.\n",
        "\n",
        "# Iterate: This process is repeated over multiple iterations (or epochs) using batches of training data until the network converges, i.e., the loss function is minimized and the model's predictions are as accurate as possible.\n",
        "\n",
        "# Example:\n",
        "# For the same cat vs. dog classification problem, if the network predicts the wrong class, backward propagation calculates the gradients of the loss function with respect to the weights. These gradients tell us how to adjust the weights to reduce the error. The weights are then updated, and the process repeats for the next batch of data.\n",
        "\n",
        "# Summary of the Steps:\n",
        "# Forward Propagation:\n",
        "\n",
        "# Input data is passed through the network.\n",
        "# Each layer calculates weighted sums, applies activation functions, and propagates the output forward.\n",
        "# The final output layer generates predictions.\n",
        "# Backward Propagation:\n",
        "\n",
        "# The loss function is computed by comparing the predictions to the true values.\n",
        "# The gradient of the loss with respect to each weight is calculated using the chain rule.\n",
        "# The weights and biases are updated to minimize the loss function using an optimization algorithm."
      ],
      "metadata": {
        "id": "mh4unodMczfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.13 What is weight initialization, and how does it impact training?"
      ],
      "metadata": {
        "id": "CN3wUDJmdDNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is Weight Initialization?\n",
        "# Weight initialization refers to the process of setting the initial values of the weights and biases in a neural network before the training begins. Proper weight initialization is crucial because it helps the network train effectively, converge faster, and avoid certain training problems like vanishing or exploding gradients.\n",
        "\n",
        "# When a neural network is initialized, the weights are typically set to small random values, and the biases can be initialized to zero or small constants. The reason for initializing weights randomly is to break the symmetry between neurons. If all weights were initialized to the same value, every neuron in a layer would learn the same features, making the network inefficient.\n",
        "\n",
        "# Why is Weight Initialization Important?\n",
        "# Breaking Symmetry: If all weights in a layer are initialized to the same value, each neuron will produce the same output during forward propagation, and they will receive the same gradient during backpropagation. This symmetry means that each neuron will learn the same features and will not be able to diversify in learning. Proper weight initialization breaks this symmetry, enabling the neurons to learn different features.\n",
        "\n",
        "# Preventing Vanishing and Exploding Gradients: The choice of weight initialization can have a significant impact on how the gradients behave during training. Improper initialization can lead to vanishing gradients (gradients too small to propagate effectively) or exploding gradients (gradients too large, causing instability), both of which hinder training.\n",
        "\n",
        "# Speeding Up Convergence: A good weight initialization can lead to faster convergence, reducing the number of epochs required to reach an optimal solution. Properly initialized weights help the model start from a good starting point, making the training process more efficient.\n",
        "\n",
        "# Avoiding Poor Local Minima: Poor initialization might cause the network to get stuck in suboptimal solutions (local minima or saddle points) during training. Starting with a better initialization can help the model find the global minimum (or a better local minimum) more effectively.\n",
        "\n",
        "# Types of Weight Initialization\n",
        "# Over the years, several strategies have been developed for initializing the weights. The choice of method depends on the activation function used and the depth of the network.\n",
        "\n",
        "# 1. Random Initialization\n",
        "# Description: The most basic form of weight initialization, where the weights are randomly assigned small values, typically drawn from a uniform or normal distribution.\n",
        "# Challenges: If the weights are too large or too small, the network might face issues like exploding or vanishing gradients. Additionally, this initialization does not account for the activation functions used in the network.\n",
        "# 2. Zero Initialization\n",
        "# Description: The weights are initialized to zero.\n",
        "# Challenges: This is generally not recommended because if all weights start at zero, all neurons in the layer will perform the same calculations and learn the same features during forward and backward propagation, leading to symmetry and inefficiency.\n",
        "# 3. Xavier/Glorot Initialization\n",
        "# Description: Designed for sigmoid or tanh activation functions, Xavier initialization (also known as Glorot initialization) sets the weights to be drawn from a distribution with a mean of zero and a variance of:\n",
        "# Var\n",
        "# (\n",
        "# ùë§\n",
        "# )\n",
        "# =\n",
        "# 2\n",
        "# number¬†of¬†input¬†units\n",
        "# +\n",
        "# number¬†of¬†output¬†units\n",
        "# Var(w)=\n",
        "# number¬†of¬†input¬†units+number¬†of¬†output¬†units\n",
        "# 2\n",
        "# ‚Äã\n",
        "\n",
        "# This method normalizes the variance of the weights based on the number of input and output units in each layer.\n",
        "# Why it works: It helps maintain the scale of the outputs as they propagate through the network, preventing gradients from vanishing or exploding.\n",
        "# Formula: If the weights are drawn from a uniform distribution, then:\n",
        "# ùë§\n",
        "# ‚àº\n",
        "# ùëà\n",
        "# (\n",
        "# ‚àí\n",
        "# 6\n",
        "# ùëõ\n",
        "# in\n",
        "# +\n",
        "# ùëõ\n",
        "# out\n",
        "# ,\n",
        "# 6\n",
        "# ùëõ\n",
        "# in\n",
        "# +\n",
        "# ùëõ\n",
        "# out\n",
        "# )\n",
        "# w‚àºU(‚àí\n",
        "# n\n",
        "# in\n",
        "# ‚Äã\n",
        "#  +n\n",
        "# out\n",
        "# ‚Äã\n",
        "\n",
        "# 6\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ,\n",
        "# n\n",
        "# in\n",
        "# ‚Äã\n",
        "#  +n\n",
        "# out\n",
        "# ‚Äã\n",
        "\n",
        "# 6\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  )\n",
        "# Where\n",
        "# ùëõ\n",
        "# in\n",
        "# n\n",
        "# in\n",
        "# ‚Äã\n",
        "#   and\n",
        "# ùëõ\n",
        "# out\n",
        "# n\n",
        "# out\n",
        "# ‚Äã\n",
        "#   are the number of input and output units in the layer, respectively.\n",
        "# Impact: It helps mitigate the vanishing/exploding gradient problem and speeds up training for networks with sigmoid or tanh activation functions.\n",
        "# 4. He Initialization\n",
        "# Description: A modification of Xavier initialization designed for ReLU and its variants. ReLU activation functions are often more prone to gradients dying out (especially if weights are too small). He initialization addresses this by setting the variance of the weights to:\n",
        "# Var\n",
        "# (\n",
        "# ùë§\n",
        "# )\n",
        "# =\n",
        "# 2\n",
        "# number¬†of¬†input¬†units\n",
        "# Var(w)=\n",
        "# number¬†of¬†input¬†units\n",
        "# 2\n",
        "\n",
        "# This provides a larger starting scale for weights, which helps ReLU neurons stay active (non-zero gradients).\n",
        "# Formula: For He initialization, weights are typically drawn from a normal distribution:\n",
        "# ùë§\n",
        "# ‚àº\n",
        "# ùëÅ\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# 2\n",
        "# ùëõ\n",
        "# in\n",
        "# )\n",
        "# w‚àºN(0,\n",
        "# n\n",
        "# in ‚Äã\n",
        "\n",
        "# 2\n",
        "#  )\n",
        "# Where\n",
        "# ùëõ\n",
        "# in\n",
        "# n\n",
        "# in‚Äã\n",
        "#   is the number of input units to the neuron.\n",
        "# Impact: This initialization is particularly effective for deep networks using ReLU activation, ensuring that gradients don't vanish too quickly and leading to better performance in deeper networks.\n",
        "# 5. LeCun Initialization\n",
        "# Description: Similar to He initialization, but designed for Leaky ReLU or ELU (Exponential Linear Units) activation functions. It normalizes the variance of weights to:\n",
        "# Var\n",
        "# (\n",
        "# ùë§\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# number¬†of¬†input¬†units\n",
        "# Var(w)=\n",
        "# number¬†of¬†input¬†units\n",
        "# 1 ‚Äã\n",
        "\n",
        "# Formula: LeCun initialization draws weights from a normal distribution:\n",
        "# ùë§\n",
        "# ‚àº\n",
        "# ùëÅ\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# 1\n",
        "# ùëõ\n",
        "# in\n",
        "# )\n",
        "# w‚àºN(0,\n",
        "# n\n",
        "# in\n",
        "\n",
        "# 1 )\n",
        "# Impact: Works well for networks that use Leaky ReLU or ELU, ensuring that the weights are neither too small nor too large and preventing gradients from becoming too small.\n",
        "# 6. Bias Initialization\n",
        "# Description: In many cases, biases are initialized to zero or small constants, but it's important to note that biases do not need to be initialized in the same way as weights.\n",
        "# Common Approach: Set the biases to zero, or sometimes a small constant like 0.1, especially if the network uses ReLU. This helps prevent neurons from being overly activated in the beginning.\n",
        "# Impact of Weight Initialization on Training\n",
        "# Convergence Speed: Proper initialization can significantly speed up the convergence of the network. For instance, using Xavier or He initialization typically leads to faster and more stable training, especially in deeper networks, compared to random or zero initialization.\n",
        "\n",
        "# Avoiding Vanishing and Exploding Gradients: Poor weight initialization can cause the gradients to either become too small (vanishing gradients) or too large (exploding gradients) during backpropagation. This prevents the network from learning effectively. He and Xavier initialization help mitigate these problems by controlling the scale of the gradients.\n",
        "\n",
        "# Training Stability: Good initialization methods lead to more stable training, as they ensure that the gradients flow properly through the network without vanishing or exploding. This means that weight updates can proceed smoothly across layers.\n",
        "\n",
        "# Better Performance in Deep Networks: As neural networks get deeper, the impact of weight initialization becomes more pronounced. Improper initialization can cause the network to fail to train effectively, especially with deep architectures. He and Xavier initialization are particularly beneficial in such cases."
      ],
      "metadata": {
        "id": "26SASTBJdJJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.14 What is the vanishing gradient problem in deep learning?"
      ],
      "metadata": {
        "id": "3OUlCd9gdXmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Vanishing Gradient Problem in Deep Learning?\n",
        "# The vanishing gradient problem is a common issue in deep neural networks during training, particularly when using gradient-based optimization methods like backpropagation. It occurs when the gradients of the loss function (with respect to the weights) become extremely small as they are propagated backward through the network layers. As a result, the weights in the earlier layers (closer to the input) receive very tiny updates, and learning in those layers stagnates, slowing or even halting the network's ability to learn.\n",
        "\n",
        "# Why Does the Vanishing Gradient Problem Happen?\n",
        "# The vanishing gradient problem primarily arises when using certain activation functions, like the sigmoid or tanh functions, which squash their input into a narrow output range. This can lead to very small gradients, especially in deep networks.\n",
        "\n",
        "# Mathematical Explanation\n",
        "# When training a neural network, the gradients are calculated using the chain rule of calculus. In a deep network with many layers, the gradient of the loss with respect to each weight is computed by multiplying gradients from each layer's output. If the gradient at each layer becomes too small, these small values are propagated backward and can become vanishingly small by the time they reach the earlier layers.\n",
        "\n",
        "# For example, let's consider a neural network with a sigmoid activation function\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# œÉ(x), which is commonly used in older networks:\n",
        "\n",
        "# Sigmoid Function:\n",
        "\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# 1\n",
        "# +\n",
        "# ùëí\n",
        "# ‚àí\n",
        "# ùë•\n",
        "# œÉ(x)=\n",
        "# 1+e\n",
        "# ‚àíx\n",
        "\n",
        "# 1‚Äã\n",
        "\n",
        "# The derivative of the sigmoid function is:\n",
        "\n",
        "# ùúé‚Ä≤\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# =\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# (\n",
        "# 1\n",
        "# ‚àí\n",
        "# ùúé\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# )\n",
        "# œÉ\n",
        "# ‚Ä≤\n",
        "#  (x)=œÉ(x)(1‚àíœÉ(x))\n",
        "# For inputs\n",
        "# ùë•\n",
        "# x that are either very large or very small, the derivative\n",
        "# ùúé\n",
        "# ‚Ä≤\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# œÉ\n",
        "# ‚Ä≤\n",
        "#  (x) approaches zero. This means that if the network's activations are in these saturated regions, the gradients will be tiny (vanishing).\n",
        "\n",
        "# Backpropagation: During backpropagation, when gradients are passed backward through each layer, the gradients can shrink exponentially. If many layers have small gradients, the resulting gradients that reach the earlier layers will be so small that the weights in those layers will barely change, making learning very slow or even impossible.\n",
        "\n",
        "# Example:\n",
        "# In a deep network, consider the following:\n",
        "\n",
        "# If each layer has a gradient smaller than 1 (due to a function like sigmoid), then after many layers, the gradient will shrink rapidly.\n",
        "# For a network with 100 layers, the gradient might shrink by a factor of\n",
        "# ùúé\n",
        "# ‚Ä≤\n",
        "# (\n",
        "# ùë•\n",
        "# )\n",
        "# œÉ\n",
        "# ‚Ä≤\n",
        "#  (x) (less than 1) at each layer. Over 100 layers, the gradient could become extremely small, even if it was reasonable in the earlier layers.\n",
        "# Impact of the Vanishing Gradient Problem\n",
        "# Slow or Stalled Training: In very deep networks, the weights in the earlier layers stop updating because the gradients become too small to make significant adjustments. As a result, the network struggles to learn from the data, and training slows down or even stalls.\n",
        "\n",
        "# Difficulty in Learning Complex Features: When earlier layers don't learn effectively, the network fails to capture important features in the data, limiting the overall performance of the model.\n",
        "\n",
        "# Failure to Converge: In extreme cases, the vanishing gradient problem can lead to a situation where the network fails to converge entirely because the gradients are so small that the weights are not updated enough to make meaningful progress.\n",
        "\n",
        "# Common Activation Functions and Their Contribution to the Problem\n",
        "# Sigmoid: The sigmoid function is often used in the past, but it can saturate quickly (i.e., for very large or small inputs, the output approaches 0 or 1), leading to very small gradients and contributing to the vanishing gradient problem.\n",
        "\n",
        "# Tanh: The tanh function is similar to sigmoid but has a broader output range (-1 to 1). However, it still saturates at extreme values of input, leading to small gradients when inputs are large or small.\n",
        "\n",
        "# ReLU (Rectified Linear Unit): While ReLU is less prone to the vanishing gradient problem, it still has issues like the dying ReLU problem, where neurons can \"die\" and stop learning if their activations are always zero. This is a different issue, but ReLU generally helps mitigate vanishing gradients compared to sigmoid or tanh.\n",
        "\n",
        "# Solutions to the Vanishing Gradient Problem\n",
        "# Several techniques have been proposed to address or mitigate the vanishing gradient problem:\n",
        "\n",
        "# Use of ReLU and Variants: ReLU and its variants (like Leaky ReLU, Parametric ReLU, and ELU) help to avoid vanishing gradients because they do not saturate (for positive inputs) and have a constant gradient (1 for positive values). This allows gradients to flow more easily through the network, even in deep architectures.\n",
        "\n",
        "# Leaky ReLU: Allows small gradients for negative inputs, helping to avoid \"dead\" neurons and improving gradient flow.\n",
        "# ELU (Exponential Linear Unit): Similar to ReLU but smoothens the negative side of the function to avoid dead neurons.\n",
        "# Batch Normalization: This technique normalizes the inputs to each layer, ensuring that the activations stay within a range that avoids saturation. By keeping activations within a reasonable range, batch normalization helps maintain healthy gradient flow through the network.\n",
        "\n",
        "# Gradient Clipping: In some cases, rather than allowing gradients to vanish, the gradients are clipped to a threshold value. This prevents gradients from exploding (another common issue) and helps stabilize training in some deep networks.\n",
        "\n",
        "# Proper Weight Initialization: Initializing weights appropriately (e.g., using Xavier or He initialization) can help prevent the gradients from becoming too small or too large. For example, He initialization is particularly effective in networks that use ReLU activation, as it helps maintain the variance of activations and gradients.\n",
        "\n",
        "# Residual Networks (ResNets): A residual network introduces \"skip connections\" that allow the gradient to bypass certain layers, which helps the gradient flow more easily through the network. This architecture has been highly successful in very deep networks and has mitigated the vanishing gradient problem by allowing gradients to \"skip\" layers.\n",
        "\n",
        "# Using Non-Saturating Activation Functions: Choosing activation functions that do not saturate, like ReLU, ensures that gradients do not approach zero, thus mitigating the vanishing gradient problem."
      ],
      "metadata": {
        "id": "t_EBwxGfdW7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.15 What is the exploding gradient problem?"
      ],
      "metadata": {
        "id": "W48PdV2Wdqxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Exploding Gradient Problem?\n",
        "# The exploding gradient problem is the opposite of the vanishing gradient problem. It occurs when the gradients of the loss function become too large during backpropagation, causing the model's weights to update with very large values. This leads to instability in training, where the model's parameters can grow excessively, making the learning process erratic and potentially causing the network to diverge (i.e., fail to converge).\n",
        "\n",
        "# Why Does the Exploding Gradient Problem Happen?\n",
        "# The exploding gradient problem typically arises when:\n",
        "\n",
        "# Large weights or large gradients propagate through the network during backpropagation, especially in very deep networks or networks with certain types of weight initialization.\n",
        "# In deep networks, the gradients are computed by multiplying values from the chain rule as they are passed backward through each layer. If the gradients are consistently large (greater than 1) at each layer, they can grow exponentially as they are propagated backward, leading to explosive values.\n",
        "# Mathematical Explanation\n",
        "# The gradient is calculated during backpropagation using the chain rule. In a deep network, the gradient of the loss function\n",
        "# ùêø\n",
        "# L with respect to the weights\n",
        "# ùë§\n",
        "# w at layer\n",
        "# ùëò\n",
        "# k is given by:\n",
        "\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùë§\n",
        "# ùëò\n",
        "# =\n",
        "# ‚àÇ\n",
        "# ùêø\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ùëÅ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ùëÅ\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ùëÅ\n",
        "# ‚ãÖ\n",
        "# ‚ãØ\n",
        "# ‚ãÖ\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ùëò\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ùëò\n",
        "# ‚àÇw\n",
        "# k\n",
        "# ‚Äã\n",
        "\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#  =\n",
        "# ‚àÇa\n",
        "# N\n",
        "# ‚Äã\n",
        "\n",
        "# ‚àÇL\n",
        "# ‚Äã\n",
        "#  ‚ãÖ\n",
        "# ‚àÇz\n",
        "# N\n",
        "# ‚Äã\n",
        "\n",
        "# ‚àÇa\n",
        "# N\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ‚ãÖ‚ãØ‚ãÖ\n",
        "# ‚àÇz\n",
        "# k\n",
        "# ‚Äã\n",
        "\n",
        "# ‚àÇa\n",
        "# k\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "\n",
        "# Where\n",
        "# ùëé\n",
        "# a represents the activations,\n",
        "# ùëß\n",
        "# z represents the weighted sums, and\n",
        "# ùëÅ\n",
        "# N is the final layer. If the product of the derivatives of the activation functions (\n",
        "# ‚àÇ\n",
        "# ùëé\n",
        "# ùëò\n",
        "# ‚àÇ\n",
        "# ùëß\n",
        "# ùëò\n",
        "# ‚àÇz\n",
        "# k\n",
        "# ‚Äã\n",
        "\n",
        "# ‚àÇa\n",
        "# k\n",
        "# ‚Äã\n",
        "\n",
        "# ‚Äã\n",
        "#  ) is greater than 1, this multiplication can cause the gradients to grow exponentially as they are propagated backward through many layers.\n",
        "\n",
        "# Example:\n",
        "# For an activation function like ReLU, the derivative is 1 for positive inputs, which doesn't cause the gradient to shrink.\n",
        "# If multiple layers in a deep network have derivatives greater than 1 (such as in sigmoid or tanh, or with large weights), the gradients can rapidly increase as they are backpropagated, resulting in large gradient values.\n",
        "# Thus, if the gradients keep multiplying by values greater than 1 across layers, the gradients will explode during backpropagation, leading to excessively large weight updates.\n",
        "\n",
        "# Impact of the Exploding Gradient Problem\n",
        "# Unstable Training: When gradients are too large, weight updates become too large, making the network's weights jump erratically. This can cause the network to become unstable and fail to converge, as the model's predictions diverge wildly.\n",
        "\n",
        "# Divergence: In extreme cases, exploding gradients can cause the model's weights to grow without bound, making the network's output and loss values diverge (i.e., the loss keeps increasing instead of decreasing), preventing training from progressing.\n",
        "\n",
        "# Numerical Instability: In practice, if the gradients are too large, they may exceed the numerical limits of the computer, leading to overflow errors (i.e., the gradients might be so large that they cannot be represented accurately in computer memory).\n",
        "\n",
        "# Overfitting and Poor Generalization: Large weight updates can lead to overfitting, where the model starts to memorize the training data rather than generalizing well. This reduces the network's ability to perform effectively on unseen data.\n",
        "\n",
        "# Causes of Exploding Gradients\n",
        "# Deep Networks: The deeper the network, the more likely it is to experience exploding gradients. In deep networks, the gradients are passed through many layers, which increases the chance that the gradients will either vanish (too small) or explode (too large).\n",
        "\n",
        "# Improper Weight Initialization: If weights are initialized with very large values, this can cause large gradients, especially in the early stages of training, making the problem worse.\n",
        "\n",
        "# Activation Functions: Some activation functions, like sigmoid and tanh, can saturate and lead to vanishing gradients, but others like ReLU or Leaky ReLU can allow large gradients to propagate if the network has large weights, leading to an exploding gradient problem.\n",
        "\n",
        "# Learning Rate: A large learning rate can exacerbate the problem of exploding gradients. If the learning rate is too high, large gradient values can cause large weight updates, leading to instability and divergence.\n",
        "\n",
        "# Solutions to the Exploding Gradient Problem\n",
        "# Several techniques have been developed to address or mitigate the exploding gradient problem:\n",
        "\n",
        "# 1. Gradient Clipping\n",
        "# One of the most effective ways to handle exploding gradients is gradient clipping. This technique involves setting a threshold value (e.g., a maximum gradient norm) and scaling down the gradients if their magnitude exceeds this threshold. This prevents the gradients from growing too large and ensures that the model stays stable.\n",
        "\n",
        "# How it works: If the norm of the gradient exceeds a certain threshold, the gradients are scaled down proportionally to keep the norm within the specified range:\n",
        "# gradient\n",
        "# =\n",
        "# gradient\n",
        "# ‚à•\n",
        "# gradient\n",
        "# ‚à•\n",
        "# ‚ãÖ\n",
        "# threshold\n",
        "# gradient=\n",
        "# ‚à•gradient‚à•\n",
        "# gradient\n",
        "# ‚Äã\n",
        "#  ‚ãÖthreshold\n",
        "# This ensures that the gradient values do not explode, even during backpropagation.\n",
        "# 2. Weight Initialization\n",
        "# Proper weight initialization can help prevent exploding gradients by ensuring that the initial weights are not too large. Some popular methods for initializing weights to avoid exploding gradients include:\n",
        "\n",
        "# Xavier/Glorot Initialization: Used for sigmoid or tanh activation functions, this initialization ensures that the weights are chosen to keep the variance of activations and gradients controlled.\n",
        "\n",
        "# He Initialization: Used for ReLU or Leaky ReLU activation functions, He initialization ensures that weights are initialized to avoid exploding gradients while maintaining good gradient flow.\n",
        "\n",
        "# 3. Smaller Learning Rate\n",
        "# Using a smaller learning rate can help control the size of weight updates. A smaller learning rate ensures that the model makes more gradual updates to the weights, reducing the risk of large updates that could lead to divergence.\n",
        "\n",
        "# 4. Batch Normalization\n",
        "# Batch normalization can help by normalizing the inputs to each layer. By keeping the activations of each layer centered around 0 with a controlled variance, batch normalization helps to ensure that the gradients do not become excessively large.\n",
        "\n",
        "# 5. Use of More Robust Architectures\n",
        "# Using architectures designed to mitigate the exploding gradient problem can also help:\n",
        "\n",
        "# Residual Networks (ResNets): ResNets include skip connections that allow the gradient to flow more easily through the layers. These skip connections help prevent both vanishing and exploding gradients by providing a direct path for gradients to flow backward.\n",
        "# 6. L2 Regularization (Weight Decay)\n",
        "# Applying L2 regularization (also known as weight decay) can help keep the weights from growing too large during training. By adding a penalty to the loss function that discourages large weights, this can indirectly help prevent the exploding gradient problem."
      ],
      "metadata": {
        "id": "Xz3QvwhJeMWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "PeZPqnqZeZmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.1 How do you create a simple perceptron for basic binary classification?"
      ],
      "metadata": {
        "id": "FNrYjpougyT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Understanding the Perceptron\n",
        "# A perceptron is a linear classifier that calculates a weighted sum of input features, applies a bias, and passes the result through a step activation function. The output is binary:\n",
        "# 0\n",
        "# 0 or\n",
        "# 1\n",
        "# 1.\n",
        "\n",
        "# Mathematically:\n",
        "\n",
        "# ùë¶\n",
        "# =\n",
        "# step\n",
        "# (\n",
        "# ùë§\n",
        "# ‚ãÖ\n",
        "# ùë•\n",
        "# +\n",
        "# ùëè\n",
        "# )\n",
        "# y=step(w‚ãÖx+b)\n",
        "# Where:\n",
        "\n",
        "# ùë§\n",
        "# w = weights\n",
        "# ùë•\n",
        "# x = input vector\n",
        "# ùëè\n",
        "# b = bias\n",
        "# step\n",
        "# (\n",
        "# ùëß\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# step(z)=1 if\n",
        "# ùëß\n",
        "# ‚â•\n",
        "# 0\n",
        "# z‚â•0, else\n",
        "# 0\n",
        "# 0\n",
        "# 2. Steps to Implement the Perceptron\n",
        "# Step 1: Import Necessary Libraries\n",
        "# python\n",
        "# Copy code\n",
        "# import numpy as np\n",
        "# Step 2: Define the Perceptron Model\n",
        "# python\n",
        "# Copy code\n",
        "# class Perceptron:\n",
        "#     def __init__(self, input_size, learning_rate=0.01, epochs=100):\n",
        "#         self.weights = np.zeros(input_size)\n",
        "#         self.bias = 0\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.epochs = epochs\n",
        "\n",
        "#     def step_function(self, z):\n",
        "#         return 1 if z >= 0 else 0\n",
        "\n",
        "#     def predict(self, x):\n",
        "#         linear_output = np.dot(self.weights, x) + self.bias\n",
        "#         return self.step_function(linear_output)\n",
        "\n",
        "#     def train(self, X, y):\n",
        "#         for _ in range(self.epochs):\n",
        "#             for xi, yi in zip(X, y):\n",
        "#                 prediction = self.predict(xi)\n",
        "#                 error = yi - prediction\n",
        "#                 # Update weights and bias\n",
        "#                 self.weights += self.learning_rate * error * xi\n",
        "#                 self.bias += self.learning_rate * error\n",
        "# Step 3: Prepare the Data\n",
        "# Example: AND logic gate (binary classification)\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# # Input features and labels\n",
        "# X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "# y = np.array([0, 0, 0, 1])\n",
        "# Step 4: Train the Perceptron\n",
        "# python\n",
        "# Copy code\n",
        "# # Create a perceptron instance\n",
        "# perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=10)\n",
        "\n",
        "# # Train the perceptron\n",
        "# perceptron.train(X, y)\n",
        "# Step 5: Test the Perceptron\n",
        "# python\n",
        "# Copy code\n",
        "# # Test on new inputs\n",
        "# for xi in X:\n",
        "#     print(f\"Input: {xi}, Predicted: {perceptron.predict(xi)}\")\n",
        "# 3. Notes\n",
        "# Linearity: The perceptron can only classify linearly separable data. For non-linear data, you need more complex models like Multi-Layer Perceptrons (MLPs).\n",
        "# Learning Rate: Determines the size of the weight updates.\n",
        "# Epochs: Number of times the entire dataset is used for training."
      ],
      "metadata": {
        "id": "qk7xNDXeg-Eq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.2 How can you build a neural network with one hidden layer using Keras?"
      ],
      "metadata": {
        "id": "kCYNkLGDNWSj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Required Libraries\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# 2. Initialize the Model\n",
        "# Use Sequential to stack layers linearly.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model = Sequential()\n",
        "# 3. Add the Input and Hidden Layer\n",
        "# Use the Dense layer for the hidden layer. Specify:\n",
        "\n",
        "# The number of neurons in the hidden layer.\n",
        "# Activation function (e.g., 'relu').\n",
        "# Input dimensions (only for the first layer).\n",
        "# python\n",
        "# Copy code\n",
        "# model.add(Dense(units=16, activation='relu', input_dim=8))  # 16 neurons, input dimension is 8\n",
        "# 4. Add the Output Layer\n",
        "# Define the number of neurons and activation function:\n",
        "\n",
        "# Regression tasks: Use one neuron with no activation or 'linear'.\n",
        "# Binary Classification: Use one neuron with 'sigmoid'.\n",
        "# Multi-class Classification: Use as many neurons as classes with 'softmax'.\n",
        "# Example for binary classification:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.add(Dense(units=1, activation='sigmoid'))  # 1 neuron for binary classification\n",
        "# 5. Compile the Model\n",
        "# Specify the optimizer, loss function, and metrics.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# 6. Train the Model\n",
        "# Use the fit method to train the model on your dataset.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "# Complete Code Example\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "\n",
        "# # Initialize the model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Add layers\n",
        "# model.add(Dense(units=16, activation='relu', input_dim=8))  # Hidden layer\n",
        "# model.add(Dense(units=1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "# This code builds a simple feedforward neural network with:\n",
        "\n",
        "# 1 input layer (implicitly defined by input_dim).\n",
        "# 1 hidden layer with 16 neurons and ReLU activation.\n",
        "# 1 output layer for binary classification."
      ],
      "metadata": {
        "id": "cxTSpFd-VNZH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.3 How do you initialize weights using the Xavier (Glorot) initialization method in Keras?"
      ],
      "metadata": {
        "id": "TWL8D9t_ZIhZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here‚Äôs how you can explicitly use Xavier (Glorot) initialization in Keras:\n",
        "\n",
        "# 1. Import the Required Modules\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.layers import Dense\n",
        "# from keras.initializers import GlorotUniform\n",
        "# 2. Use GlorotUniform in a Layer\n",
        "# When defining a layer, you can specify the weight initializer using the kernel_initializer parameter.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# layer = Dense(units=16, activation='relu', kernel_initializer=GlorotUniform())\n",
        "# 3. Example Neural Network with Xavier Initialization\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.initializers import GlorotUniform\n",
        "\n",
        "# # Initialize the model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Add layers with Xavier initialization\n",
        "# model.add(Dense(units=16, activation='relu', kernel_initializer=GlorotUniform(), input_dim=8))\n",
        "# model.add(Dense(units=1, activation='sigmoid', kernel_initializer=GlorotUniform()))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "# 4. Additional Notes\n",
        "# Bias Initialization: Biases are typically initialized to zeros by default in Keras, which is often sufficient. If needed, you can set the bias_initializer explicitly.\n",
        "# Other Glorot Variants:\n",
        "# GlorotNormal: Initializes weights from a normal distribution.\n",
        "# GlorotUniform: Initializes weights from a uniform distribution (default for many layers).\n",
        "# For example, using GlorotNormal:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.initializers import GlorotNormal\n",
        "# layer = Dense(units=16, activation='relu', kernel_initializer=GlorotNormal())"
      ],
      "metadata": {
        "id": "udHdEcFXZNT1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#.4 How can you apply different activation functions in a neural network in Keras?"
      ],
      "metadata": {
        "id": "Ugzr_yPPZeQt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here‚Äôs how you can apply different activation functions in a neural network:\n",
        "\n",
        "# 1. Import Required Modules\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# 2. Specify Activation Functions for Each Layer\n",
        "# Define each layer with its activation function using the activation parameter in the Dense layer.\n",
        "\n",
        "# Example:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model = Sequential()\n",
        "\n",
        "# # Input and first hidden layer with ReLU activation\n",
        "# model.add(Dense(units=16, activation='relu', input_dim=8))\n",
        "\n",
        "# # Second hidden layer with tanh activation\n",
        "# model.add(Dense(units=12, activation='tanh'))\n",
        "\n",
        "# # Output layer for binary classification with sigmoid activation\n",
        "# model.add(Dense(units=1, activation='sigmoid'))\n",
        "# 3. Common Activation Functions in Keras\n",
        "# Here are some commonly used activation functions and when to use them:\n",
        "\n",
        "# ReLU (relu): For hidden layers in most networks.\n",
        "# Sigmoid (sigmoid): For binary classification outputs.\n",
        "# Softmax (softmax): For multi-class classification outputs.\n",
        "# Tanh (tanh): For hidden layers where inputs range between -1 and 1.\n",
        "# Linear (linear): For regression outputs or custom activations.\n",
        "# 4. Full Example\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "\n",
        "# # Initialize the model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Add layers with different activation functions\n",
        "# model.add(Dense(units=16, activation='relu', input_dim=8))  # ReLU for hidden layer\n",
        "# model.add(Dense(units=12, activation='tanh'))               # Tanh for another hidden layer\n",
        "# model.add(Dense(units=1, activation='sigmoid'))             # Sigmoid for output layer\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "# 5. Custom Activation Functions\n",
        "# You can also define your custom activation functions using the keras.layers.Activation layer or directly in TensorFlow/Keras.\n",
        "\n",
        "# Example:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.layers import Activation\n",
        "# from keras import backend as K\n",
        "\n",
        "# # Custom activation: Swish\n",
        "# def swish(x):\n",
        "#     return x * K.sigmoid(x)\n",
        "\n",
        "# # Use the custom activation in a layer\n",
        "# model.add(Dense(units=16))\n",
        "# model.add(Activation(swish))  # Add custom activation\n",
        "# 6. Tips for Choosing Activation Functions\n",
        "# Use ReLU (or its variants like Leaky ReLU) for hidden layers to avoid vanishing gradient problems.\n",
        "# Use sigmoid or softmax in the output layer depending on your task:\n",
        "# Binary classification: sigmoid.\n",
        "# Multi-class classification: softmax.\n",
        "# Avoid sigmoid and tanh in hidden layers unless specifically needed, as they can lead to vanishing gradients for deep networks."
      ],
      "metadata": {
        "id": "dCJodPH4cSri"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.5 How do you add dropout to a neural network model to prevent overfitting?"
      ],
      "metadata": {
        "id": "l_LPc0hIcnhH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Keras, you can add dropout layers using the Dropout class.\n",
        "\n",
        "# Steps to Add Dropout to a Neural Network\n",
        "# 1. Import the Dropout Layer\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.layers import Dropout\n",
        "# 2. Add Dropout Layers\n",
        "# Insert a Dropout layer after a dense (or other) layer in your network. The rate parameter specifies the fraction of neurons to drop (e.g., 0.2 means 20% of neurons will be randomly set to 0 during training).\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.add(Dense(units=16, activation='relu', input_dim=8))  # Dense layer\n",
        "# model.add(Dropout(rate=0.2))  # Dropout layer with 20% dropout\n",
        "# 3. Full Example: Neural Network with Dropout\n",
        "# Below is a complete example of adding dropout to a neural network:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout\n",
        "\n",
        "# # Initialize the model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Input layer and first hidden layer with Dropout\n",
        "# model.add(Dense(units=64, activation='relu', input_dim=20))  # Dense layer\n",
        "# model.add(Dropout(rate=0.3))  # Dropout layer (30% neurons dropped)\n",
        "\n",
        "# # Second hidden layer with Dropout\n",
        "# model.add(Dense(units=32, activation='relu'))  # Dense layer\n",
        "# model.add(Dropout(rate=0.5))  # Dropout layer (50% neurons dropped)\n",
        "\n",
        "# # Output layer\n",
        "# model.add(Dense(units=1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "# 4. Key Considerations\n",
        "# Where to Add Dropout:\n",
        "\n",
        "# Typically added after dense or convolutional layers.\n",
        "# Avoid adding dropout to the output layer.\n",
        "# Dropout Rates:\n",
        "\n",
        "# Common rates: 0.2 (20%) to 0.5 (50%).\n",
        "# Higher dropout rates can be used for smaller models or more complex data prone to overfitting.\n",
        "# During Training vs. Testing:\n",
        "\n",
        "# Dropout is only applied during training. At test time, all neurons are active, and their outputs are scaled by the dropout rate automatically.\n",
        "# 5. Dropout in Other Layer Types\n",
        "# You can also add dropout to other layer types, like recurrent neural networks (RNNs), using their specific dropout arguments.\n",
        "\n",
        "# Example for LSTM:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.layers import LSTM\n",
        "\n",
        "# model.add(LSTM(units=50, dropout=0.2, recurrent_dropout=0.2))  # Dropout for input and recurrent connections"
      ],
      "metadata": {
        "id": "R_yOG_GGc7Bf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.6 How do you manually implement forward propagation in a simple neural network?"
      ],
      "metadata": {
        "id": "Dkpygi0ideoe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here‚Äôs a step-by-step guide:\n",
        "\n",
        "# 1. Define the Neural Network Structure\n",
        "# Assume:\n",
        "\n",
        "# An input layer with\n",
        "# ùëõ\n",
        "# n features.\n",
        "# A single hidden layer with\n",
        "# ‚Ñé\n",
        "# h neurons.\n",
        "# An output layer with\n",
        "# ùëú\n",
        "# o neurons.\n",
        "# 2. Required Components\n",
        "# You need:\n",
        "\n",
        "# Inputs (\n",
        "# ùëã\n",
        "# X): The data passed to the network.\n",
        "# Weights (\n",
        "# ùëä\n",
        "# W): The parameters connecting neurons between layers.\n",
        "# Biases (\n",
        "# ùëè\n",
        "# b): The offset added to the weighted sum of inputs.\n",
        "# Activation Functions: Functions applied to the output of each layer.\n",
        "# 3. Mathematical Operations for Forward Propagation\n",
        "# For a simple network:\n",
        "\n",
        "# Hidden Layer Computation:\n",
        "\n",
        "# ùëç\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# =\n",
        "# ùëä\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# ùëã\n",
        "# +\n",
        "# ùëè\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# Z\n",
        "# [1]\n",
        "#  =W\n",
        "# [1]\n",
        "#  X+b\n",
        "# [1]\n",
        "\n",
        "# ùê¥\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# =\n",
        "# Activation\n",
        "# (\n",
        "# ùëç\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# )\n",
        "# A\n",
        "# [1]\n",
        "#  =Activation(Z\n",
        "# [1]\n",
        "#  )\n",
        "# Output Layer Computation:\n",
        "\n",
        "# ùëç\n",
        "# [\n",
        "# 2\n",
        "# ]\n",
        "# =\n",
        "# ùëä\n",
        "# [\n",
        "# 2\n",
        "# ]\n",
        "# ùê¥\n",
        "# [\n",
        "# 1\n",
        "# ]\n",
        "# +\n",
        "# ùëè\n",
        "# [\n",
        "# 2\n",
        "# ]\n",
        "# Z\n",
        "# [2]\n",
        "#  =W\n",
        "# [2]\n",
        "#  A\n",
        "# [1]\n",
        "#  +b\n",
        "# [2]\n",
        "\n",
        "# ùê¥\n",
        "# [\n",
        "# 2\n",
        "# ]\n",
        "# =\n",
        "# Activation\n",
        "# (\n",
        "# ùëç\n",
        "# [\n",
        "# 2\n",
        "# ]\n",
        "# )\n",
        "# A\n",
        "# [2]\n",
        "#  =Activation(Z\n",
        "# [2]\n",
        "#  )\n",
        "# Here,\n",
        "# ùëç\n",
        "# Z represents the linear combination, and\n",
        "# ùê¥\n",
        "# A is the activation output.\n",
        "\n",
        "# 4. Manual Implementation in Python\n",
        "# Let‚Äôs implement a simple example with:\n",
        "\n",
        "# Input layer: 3 features\n",
        "# Hidden layer: 4 neurons with ReLU activation\n",
        "# Output layer: 1 neuron with sigmoid activation\n",
        "# python\n",
        "# Copy code\n",
        "# import numpy as np\n",
        "\n",
        "# # Define inputs (1 sample with 3 features)\n",
        "# X = np.array([[1.0, 0.5, -1.5]])\n",
        "\n",
        "# # Initialize weights and biases\n",
        "# np.random.seed(42)\n",
        "# W1 = np.random.randn(4, 3)  # Weights for hidden layer (4 neurons, 3 inputs)\n",
        "# b1 = np.random.randn(4, 1)  # Biases for hidden layer (4 neurons)\n",
        "\n",
        "# W2 = np.random.randn(1, 4)  # Weights for output layer (1 neuron, 4 inputs from hidden)\n",
        "# b2 = np.random.randn(1, 1)  # Bias for output layer (1 neuron)\n",
        "\n",
        "# # Define activation functions\n",
        "# def relu(z):\n",
        "#     return np.maximum(0, z)\n",
        "\n",
        "# def sigmoid(z):\n",
        "#     return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# # Forward propagation\n",
        "# # Hidden layer\n",
        "# Z1 = np.dot(W1, X.T) + b1  # Linear combination\n",
        "# A1 = relu(Z1)              # Activation\n",
        "\n",
        "# # Output layer\n",
        "# Z2 = np.dot(W2, A1) + b2   # Linear combination\n",
        "# A2 = sigmoid(Z2)           # Activation\n",
        "\n",
        "# # Output\n",
        "# print(\"Output of the network:\", A2)\n",
        "# 5. Explanation of Code\n",
        "# Input Shape:\n",
        "# ùëã\n",
        "# X has shape\n",
        "# (\n",
        "# 1\n",
        "# ,\n",
        "# 3\n",
        "# )\n",
        "# (1,3) because it contains 1 sample with 3 features.\n",
        "# Weight Shapes:\n",
        "# ùëä\n",
        "# 1\n",
        "# W1:\n",
        "# (\n",
        "# 4\n",
        "# ,\n",
        "# 3\n",
        "# )\n",
        "# (4,3) (4 neurons in the hidden layer, 3 inputs).\n",
        "# ùëä\n",
        "# 2\n",
        "# W2:\n",
        "# (\n",
        "# 1\n",
        "# ,\n",
        "# 4\n",
        "# )\n",
        "# (1,4) (1 output neuron, 4 inputs from the hidden layer).\n",
        "# Bias Shapes:\n",
        "# ùëè\n",
        "# 1\n",
        "# b1:\n",
        "# (\n",
        "# 4\n",
        "# ,\n",
        "# 1\n",
        "# )\n",
        "# (4,1) (4 neurons in the hidden layer).\n",
        "# ùëè\n",
        "# 2\n",
        "# b2:\n",
        "# (\n",
        "# 1\n",
        "# ,\n",
        "# 1\n",
        "# )\n",
        "# (1,1) (1 output neuron).\n",
        "# Matrix Multiplication:\n",
        "# ùëç\n",
        "# 1\n",
        "# =\n",
        "# ùëä\n",
        "# 1\n",
        "# ‚ãÖ\n",
        "# ùëã\n",
        "# ùëá\n",
        "# +\n",
        "# ùëè\n",
        "# 1\n",
        "# Z1=W1‚ãÖX\n",
        "# T\n",
        "#  +b1: Computes the linear combination for the hidden layer.\n",
        "# ùê¥\n",
        "# 1\n",
        "# =\n",
        "# ReLU\n",
        "# (\n",
        "# ùëç\n",
        "# 1\n",
        "# )\n",
        "# A1=ReLU(Z1): Applies activation function.\n",
        "# Similarly for the output layer.\n",
        "# 6. Output Example\n",
        "# With random weights and biases, the output might look like this:\n",
        "\n",
        "# lua\n",
        "# Copy code\n",
        "# Output of the network: [[0.847]]\n",
        "# This is the probability output of the network if using a sigmoid activation in the final layer.\n",
        "\n",
        "# 7. Notes\n",
        "# Activation Functions:\n",
        "\n",
        "# Hidden layers often use ReLU or its variants.\n",
        "# Output layer uses sigmoid (binary classification) or softmax (multi-class classification).\n",
        "# Scalability: This example is for a single sample. For batch processing, ensure shapes are consistent when multiplying.\n",
        "\n",
        "# Backward Propagation: To train the model, you would calculate the loss and perform backpropagation to update weights and biases."
      ],
      "metadata": {
        "id": "FI3v90LyeK62"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.7 How do you add batch normalization to a neural network model in Keras?"
      ],
      "metadata": {
        "id": "GRHOZPTdedMO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the Required Module\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.layers import BatchNormalization\n",
        "# 2. Add BatchNormalization Layers\n",
        "# Batch normalization can be added after a layer (typically after the weights and before the activation function).\n",
        "\n",
        "# Example for Dense Layers\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, BatchNormalization, ReLU\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # Input and first hidden layer\n",
        "# model.add(Dense(units=64, input_dim=20))  # Dense layer\n",
        "# model.add(BatchNormalization())          # Batch normalization\n",
        "# model.add(ReLU())                        # Activation function\n",
        "\n",
        "# # Second hidden layer\n",
        "# model.add(Dense(units=32))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(ReLU())\n",
        "\n",
        "# # Output layer\n",
        "# model.add(Dense(units=1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "# 3. Using Batch Normalization in Convolutional Layers\n",
        "# For convolutional neural networks (CNNs), you can add batch normalization after a convolutional layer:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Conv2D, Flatten, Dense, BatchNormalization, MaxPooling2D\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # Convolutional layer\n",
        "# model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "# model.add(BatchNormalization())  # Batch normalization\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# # Flatten and dense layers\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(units=128))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(ReLU())\n",
        "# model.add(Dense(units=1, activation='sigmoid'))\n",
        "# 4. Notes on Where to Add Batch Normalization\n",
        "# Before or After Activation:\n",
        "\n",
        "# Batch normalization is often added before the activation function:\n",
        "# Dense/Conv layer ‚Üí BatchNormalization ‚Üí Activation\n",
        "# Alternatively, it can be added after the activation, depending on preference or specific network design.\n",
        "# Parameter Updates:\n",
        "\n",
        "# Batch normalization introduces learnable parameters: scale (gamma) and shift (beta).\n",
        "# These parameters allow the network to learn the optimal normalization dynamically.\n",
        "# Dropout with Batch Normalization:\n",
        "\n",
        "# If you're using dropout, it is typically added after batch normalization.\n",
        "# 5. Compile and Train the Model\n",
        "# Compile and train the model as usual:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "# 6. Advantages of Batch Normalization\n",
        "# Normalizes intermediate activations, reducing internal covariate shift.\n",
        "# Allows for higher learning rates and faster convergence.\n",
        "# Acts as a regularizer, reducing the need for dropout in some cases.\n",
        "# Helps mitigate the vanishing/exploding gradient problem."
      ],
      "metadata": {
        "id": "IxOVs1dkfXui"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.8 How can you visualize the training process with accuracy and loss curves?"
      ],
      "metadata": {
        "id": "sO8T2n5tfe-a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's a step-by-step guide to visualize the training process:\n",
        "\n",
        "# 1. Train the Model and Save the History\n",
        "# The fit method returns a History object that contains the performance metrics.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# history = model.fit(\n",
        "#     X_train, y_train,\n",
        "#     epochs=50,\n",
        "#     batch_size=32,\n",
        "#     validation_split=0.2\n",
        "# )\n",
        "# 2. Extract Accuracy and Loss Data\n",
        "# The history.history dictionary contains the training and validation metrics.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# train_loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "# train_acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "# 3. Plot the Accuracy and Loss Curves\n",
        "# Use Matplotlib to create the visualizations.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Plot training and validation loss\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(train_loss, label='Training Loss', color='blue')\n",
        "# plt.plot(val_loss, label='Validation Loss', color='orange')\n",
        "# plt.title('Loss Curves')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # Plot training and validation accuracy\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(train_acc, label='Training Accuracy', color='green')\n",
        "# plt.plot(val_acc, label='Validation Accuracy', color='red')\n",
        "# plt.title('Accuracy Curves')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "# 4. Explanation of the Plots\n",
        "# Loss Curve:\n",
        "\n",
        "# Training Loss: Indicates how well the model is fitting the training data.\n",
        "# Validation Loss: Indicates how well the model generalizes to unseen data.\n",
        "# Look for overfitting if the validation loss starts increasing while the training loss continues decreasing.\n",
        "# Accuracy Curve:\n",
        "\n",
        "# Training Accuracy: Measures accuracy on the training set.\n",
        "# Validation Accuracy: Measures accuracy on the validation set.\n",
        "# A significant gap between training and validation accuracy may indicate overfitting.\n",
        "# 5. Example Output\n",
        "# A typical output would look like this:\n",
        "\n",
        "# Loss Curve: Starts high and decreases over epochs. Validation loss may start to diverge if overfitting occurs.\n",
        "# Accuracy Curve: Starts low and increases over epochs. Validation accuracy may plateau if the model has converged.\n",
        "# 6. Save the Plots (Optional)\n",
        "# You can save the plots as images using Matplotlib:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# plt.savefig('accuracy_curve.png')\n",
        "# plt.savefig('loss_curve.png')\n",
        "# 7. Tips for Interpretation\n",
        "# Smooth Curves: If the curves fluctuate heavily, consider lowering the learning rate or increasing batch size.\n",
        "# Validation Metrics: If the validation accuracy is much lower than training accuracy, try adding regularization (e.g., dropout or weight decay) or more data augmentation."
      ],
      "metadata": {
        "id": "4xajf4CKfzAC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.9 How can you use gradient clipping in Keras to control the gradient size and prevent exploding gradients?"
      ],
      "metadata": {
        "id": "5TZtolMXf5ey"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Keras, you can apply gradient clipping by setting the clipvalue or clipnorm parameters when defining an optimizer.\n",
        "\n",
        "# 1. Types of Gradient Clipping\n",
        "# Clipping by Value (clipvalue): Caps all gradients element-wise to a maximum absolute value.\n",
        "# If a gradient exceeds the specified value, it is set to that maximum value.\n",
        "# Clipping by Norm (clipnorm): Scales the gradient vector if its L2 norm exceeds a threshold.\n",
        "# This ensures the entire gradient vector‚Äôs norm is within the threshold.\n",
        "# 2. Applying Gradient Clipping\n",
        "# You can apply gradient clipping when creating an optimizer in Keras.\n",
        "\n",
        "# Clipping by Value\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# # Define an optimizer with gradient clipping by value\n",
        "# optimizer = Adam(learning_rate=0.001, clipvalue=1.0)\n",
        "# Clipping by Norm\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# # Define an optimizer with gradient clipping by norm\n",
        "# optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "# 3. Using the Optimizer with Gradient Clipping\n",
        "# Once the optimizer is configured, pass it to the compile method of your model:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# 4. Full Example: Gradient Clipping in Action\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, LSTM\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# # Define a simple LSTM model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(units=50, input_shape=(10, 1), return_sequences=True))\n",
        "# model.add(LSTM(units=50))\n",
        "# model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# # Define an optimizer with gradient clipping by norm\n",
        "# optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "# 5. Key Points\n",
        "# Choosing Clipping Values:\n",
        "# For clipvalue, values like 1.0 or 0.5 are common.\n",
        "# For clipnorm, values like 1.0 to 5.0 are typical.\n",
        "# When to Use Gradient Clipping:\n",
        "# Use for deep networks, RNNs, or models where you observe unstable gradients (e.g., loss diverging to NaN).\n",
        "# Impact on Training:\n",
        "# Gradient clipping helps stabilize training but might slow convergence slightly due to restricted updates.\n",
        "# 6. Why Gradient Clipping Works\n",
        "# Gradient clipping controls the size of gradients, ensuring that updates to weights remain within a manageable range. This prevents instability caused by excessively large gradients, especially in situations like:\n",
        "\n",
        "# Long sequences in RNNs.\n",
        "# Poorly initialized weights."
      ],
      "metadata": {
        "id": "5SQD_aOvgAkJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.10 How can you create a custom loss function in Keras?"
      ],
      "metadata": {
        "id": "_3S6O7G6gRWR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here‚Äôs how you can create and use a custom loss function in Keras:\n",
        "\n",
        "# 1. Steps to Create a Custom Loss Function\n",
        "# Basic Form of a Loss Function\n",
        "# A custom loss function is a Python function that has the following signature:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# def custom_loss(y_true, y_pred):\n",
        "#     loss = ...  # Calculate the loss\n",
        "#     return loss\n",
        "# y_true: True labels (ground truth).\n",
        "# y_pred: Predicted outputs from the model.\n",
        "# Example: Mean Squared Error (Custom Implementation)\n",
        "# python\n",
        "# Copy code\n",
        "# import tensorflow as tf\n",
        "\n",
        "# def custom_mse(y_true, y_pred):\n",
        "#     return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "# 2. Use the Custom Loss Function\n",
        "# Pass the custom loss function to the compile method of the model.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.compile(optimizer='adam', loss=custom_mse, metrics=['accuracy'])\n",
        "# 3. Full Example\n",
        "# Here‚Äôs an example of using a custom loss function in a regression task:\n",
        "\n",
        "# Define the Model\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Define a simple model\n",
        "# model = Sequential([\n",
        "#     Dense(64, activation='relu', input_dim=10),\n",
        "#     Dense(1, activation='linear')\n",
        "# ])\n",
        "# Define the Custom Loss Function\n",
        "# python\n",
        "# Copy code\n",
        "# def custom_huber_loss(y_true, y_pred, delta=1.0):\n",
        "#     \"\"\"Huber loss function: less sensitive to outliers than MSE.\"\"\"\n",
        "#     error = y_true - y_pred\n",
        "#     is_small_error = tf.abs(error) <= delta\n",
        "#     squared_loss = 0.5 * tf.square(error)\n",
        "#     linear_loss = delta * tf.abs(error) - 0.5 * delta**2\n",
        "#     return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "# Compile the Model with the Custom Loss\n",
        "# python\n",
        "# Copy code\n",
        "# model.compile(optimizer='adam', loss=lambda y_true, y_pred: custom_huber_loss(y_true, y_pred, delta=1.0))\n",
        "# Train the Model\n",
        "# python\n",
        "# Copy code\n",
        "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "# 4. Additional Notes\n",
        "# TensorFlow Operations:\n",
        "\n",
        "# Always use TensorFlow operations (e.g., tf.reduce_mean, tf.square) inside the custom loss function for compatibility with TensorFlow's computational graph.\n",
        "# Parameterizing Loss Functions:\n",
        "\n",
        "# If your custom loss function has additional parameters (e.g., delta in the Huber loss), you can use a wrapper function or a lambda function:\n",
        "# python\n",
        "# Copy code\n",
        "# def custom_loss_with_param(delta):\n",
        "#     def loss(y_true, y_pred):\n",
        "#         return custom_huber_loss(y_true, y_pred, delta)\n",
        "#     return loss\n",
        "\n",
        "# model.compile(optimizer='adam', loss=custom_loss_with_param(delta=1.0))\n",
        "# Custom Loss Classes:\n",
        "\n",
        "# For more complex losses, you can define a custom loss as a class by subclassing keras.losses.Loss:\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.losses import Loss\n",
        "\n",
        "# class CustomHuberLoss(Loss):\n",
        "#     def __init__(self, delta=1.0):\n",
        "#         super().__init__()\n",
        "#         self.delta = delta\n",
        "\n",
        "#     def call(self, y_true, y_pred):\n",
        "#         error = y_true - y_pred\n",
        "#         is_small_error = tf.abs(error) <= self.delta\n",
        "#         squared_loss = 0.5 * tf.square(error)\n",
        "#         linear_loss = self.delta * tf.abs(error) - 0.5 * self.delta**2\n",
        "#         return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "# model.compile(optimizer='adam', loss=CustomHuberLoss(delta=1.0))\n",
        "# 5. Debugging Custom Loss Functions\n",
        "# To debug a custom loss function:\n",
        "\n",
        "# Print y_true and y_pred inside the function to verify shapes and values.\n",
        "# Use a small dataset to validate the loss function outputs."
      ],
      "metadata": {
        "id": "LLN-yR8qgrLI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.11 How can you visualize the structure of a neural network model in Keras?"
      ],
      "metadata": {
        "id": "0xZ28OidguPg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Summary of the Model Structure\n",
        "# Use the summary() method to get a text-based overview of the model.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model.summary()\n",
        "# This will display:\n",
        "\n",
        "# Layer names and types.\n",
        "# Output shapes for each layer.\n",
        "# Number of parameters (trainable and non-trainable).\n",
        "# Example Output:\n",
        "\n",
        "# markdown\n",
        "# Copy code\n",
        "# Model: \"sequential\"\n",
        "# _________________________________________________________________\n",
        "#  Layer (type)                Output Shape              Param #\n",
        "# =================================================================\n",
        "#  dense (Dense)               (None, 64)               640\n",
        "#  dense_1 (Dense)             (None, 32)               2080\n",
        "#  dense_2 (Dense)             (None, 1)                33\n",
        "# =================================================================\n",
        "# Total params: 2,753\n",
        "# Trainable params: 2,753\n",
        "# Non-trainable params: 0\n",
        "# _________________________________________________________________\n",
        "# 2. Visualize with plot_model\n",
        "# Keras provides the plot_model function to generate a graphical representation of the model.\n",
        "\n",
        "# Steps:\n",
        "# Import plot_model:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.utils import plot_model\n",
        "# Generate and Save the Diagram:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# plot_model(model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)\n",
        "# Parameters of plot_model:\n",
        "\n",
        "# to_file: The filename to save the visualization.\n",
        "# show_shapes: Displays the output shape of each layer.\n",
        "# show_layer_names: Displays the names of the layers.\n",
        "# Example Diagram:\n",
        "# Layers are represented as nodes.\n",
        "# Connections between layers represent data flow.\n",
        "# If show_shapes=True, the diagram will include the input/output shapes for each layer.\n",
        "# 3. Interactive Visualization with TensorBoard\n",
        "# You can use TensorBoard to visualize the model interactively.\n",
        "\n",
        "# Steps:\n",
        "# Log Model Graph:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# from keras.callbacks import TensorBoard\n",
        "\n",
        "# # Define TensorBoard callback\n",
        "# tensorboard_callback = TensorBoard(log_dir=\"logs\", histogram_freq=1)\n",
        "\n",
        "# # Train the model with the callback\n",
        "# model.fit(X_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "# Launch TensorBoard: Run the following command in your terminal:\n",
        "\n",
        "# bash\n",
        "# Copy code\n",
        "# tensorboard --logdir logs\n",
        "# Access the Graph: Open the URL (e.g., http://localhost:6006) in a web browser to view the interactive graph of the model.\n",
        "\n",
        "# 4. Print Model as a JSON or YAML\n",
        "# JSON Format:\n",
        "# You can save the model architecture in JSON format for external visualization tools.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# YAML Format:\n",
        "# python\n",
        "# Copy code\n",
        "# model_yaml = model.to_yaml()\n",
        "# with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "#     yaml_file.write(model_yaml)\n",
        "# You can use these files to load or analyze the model structure in external applications.\n",
        "\n",
        "# 5. Visualize Layers with Code\n",
        "# You can manually loop through the model's layers to understand their details.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# for layer in model.layers:\n",
        "#     print(f\"Layer Name: {layer.name}\")\n",
        "#     print(f\"Layer Type: {layer.__class__.__name__}\")\n",
        "#     print(f\"Input Shape: {layer.input_shape}\")\n",
        "#     print(f\"Output Shape: {layer.output_shape}\")\n",
        "#     print(f\"Number of Parameters: {layer.count_params()}\")\n",
        "#     print(\"--------------------------------------------------\")\n",
        "# 6. Third-Party Tools for Advanced Visualization\n",
        "# Netron:\n",
        "\n",
        "# Install Netron:\n",
        "# bash\n",
        "# Copy code\n",
        "# pip install netron\n",
        "# Open the model file:\n",
        "# python\n",
        "# Copy code\n",
        "# import netron\n",
        "# netron.start(\"model.h5\")  # or model.onnx, model.pb\n",
        "# Graphviz (via plot_model):\n",
        "\n",
        "# Install Graphviz:\n",
        "# bash\n",
        "# Copy code\n",
        "# sudo apt install graphviz\n",
        "# pip install graphviz\n",
        "# 7. When to Use Each Method\n",
        "# Text Summary (summary()): For a quick and simple overview of the model.\n",
        "# Graphical Representation (plot_model): For detailed visualization of the architecture.\n",
        "# TensorBoard: For an interactive exploration of the model and its training process.\n",
        "# Netron: For external advanced visualization and debugging."
      ],
      "metadata": {
        "id": "y7WEA7C6hI-v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5ZEE-88hKVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}